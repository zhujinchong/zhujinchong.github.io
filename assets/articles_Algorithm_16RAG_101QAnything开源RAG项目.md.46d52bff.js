import{_ as s,o as e,c as a,Q as n}from"./chunks/framework.2516552c.js";const t="/assets/qanything_arch.a8ecb7bf.png",l="/assets/two_stage_retrieval.1ab93c45.jpg",q=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"articles/Algorithm/16RAG/101QAnything开源RAG项目.md","filePath":"articles/Algorithm/16RAG/101QAnything开源RAG项目.md","lastUpdated":null}'),r={name:"articles/Algorithm/16RAG/101QAnything开源RAG项目.md"},o=n('<blockquote><p>参考网易开源的RAG项目</p></blockquote><h2 id="项目流程图" tabindex="-1">项目流程图 <a class="header-anchor" href="#项目流程图" aria-label="Permalink to &quot;项目流程图&quot;">​</a></h2><p><img src="'+t+'" alt="qanything_system"></p><h2 id="为什么两阶段检索" tabindex="-1">为什么两阶段检索 <a class="header-anchor" href="#为什么两阶段检索" aria-label="Permalink to &quot;为什么两阶段检索&quot;">​</a></h2><p>知识库数据量大的场景下两阶段优势非常明显，如果只用一阶段embedding检索，随着数据量增大会出现检索退化的问题，如下图中绿线所示，二阶段rerank重排后能实现准确率稳定增长，即<strong>数据越多，效果越好</strong>。</p><p><img src="'+l+`" alt="two stage retrievaal"></p><h2 id="什么是query-understand" tabindex="-1">什么是Query Understand <a class="header-anchor" href="#什么是query-understand" aria-label="Permalink to &quot;什么是Query Understand&quot;">​</a></h2><p>query understand主要是用于解决<strong>多轮对话</strong>和<strong>意图识别</strong>的一个环节。</p><p>多轮对话举例</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">query1: 清华大学怎么样？answer1:清华大学xxx</span></span>
<span class="line"><span style="color:#e1e4e8;">query2: 和北京大学比呢？</span></span>
<span class="line"><span style="color:#e1e4e8;">发现问题：此时用query2去检索，得到的全是北大的信息，回答有问题。</span></span>
<span class="line"><span style="color:#e1e4e8;">解决方法：</span></span>
<span class="line"><span style="color:#e1e4e8;">把历史对话和当前问题改写成一个独立问题，比如这里会改写成condense query: 清华大学和北京大学相比怎么样？</span></span>
<span class="line"><span style="color:#e1e4e8;">因为LLM有幻觉，这个condense query会被改错，所以最终回答还是用history + query2 + retrieval_docs</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">query1: 清华大学怎么样？answer1:清华大学xxx</span></span>
<span class="line"><span style="color:#24292e;">query2: 和北京大学比呢？</span></span>
<span class="line"><span style="color:#24292e;">发现问题：此时用query2去检索，得到的全是北大的信息，回答有问题。</span></span>
<span class="line"><span style="color:#24292e;">解决方法：</span></span>
<span class="line"><span style="color:#24292e;">把历史对话和当前问题改写成一个独立问题，比如这里会改写成condense query: 清华大学和北京大学相比怎么样？</span></span>
<span class="line"><span style="color:#24292e;">因为LLM有幻觉，这个condense query会被改错，所以最终回答还是用history + query2 + retrieval_docs</span></span></code></pre></div><p>意图分类</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">有些问题不适合RAG回答，LLM自己就可以回答，或者有些问题需要查询MySQL库，这里用于分流问题。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">有些问题不适合RAG回答，LLM自己就可以回答，或者有些问题需要查询MySQL库，这里用于分流问题。</span></span></code></pre></div>`,12),p=[o];function c(i,d,h,y,u,_){return e(),a("div",null,p)}const m=s(r,[["render",c]]);export{q as __pageData,m as default};
