import{_ as s,o as e,c as a,Q as n}from"./chunks/framework.2516552c.js";const t="/assets/640-1690696184284.c48f8bc6.png",m=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"articles/Algorithm/12LLM/25Stanford Alpaca.md","filePath":"articles/Algorithm/12LLM/25Stanford Alpaca.md","lastUpdated":null}'),o={name:"articles/Algorithm/12LLM/25Stanford Alpaca.md"},p=n(`<p>时间：20230511</p><p>概述：</p><p>近日，Meta开源了他们的LLaMA系列模型，包含了参数量为7B/13B/33B/65B的不同模型，然而，原模型的效果较差（如生成的结果文不对题、以及无法自然地结束生成等）。因此，斯坦福的 Alpaca 模型基于 LLaMA-7B 和指令微调，仅使用约 5 万条训练数据，就能达到类似 GPT-3.5 的效果。</p><p>引言：</p><p>对于斯坦福的团队来说，想要在预算内训练一个高质量的指令遵循模型，就必须面临2个重要的挑战：要有一个强大的预训练语言模型，以及一个高质量的指令遵循数据。</p><p>恰恰，提供给学术研究人员使用的LLaMA模型搞定了第一个问题。</p><p>对于第二个挑战，「Self-Instruct: Aligning Language Model with Self Generated Instructions」论文给了很好的启发，即使用现有的强语言模型来自动生成指令数据。</p><p>方法：</p><p>该项目提供了廉价的对LLaMA模型进行微调的方法，大体思路如下：</p><p>1、首先，利用OpenAI提供的GPT模型API生成质量较高的指令数据（仅52k），例如：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">{</span></span>
<span class="line"><span style="color:#e1e4e8;">    &quot;instruction&quot;: &quot;Rewrite the following sentence in the third person&quot;,</span></span>
<span class="line"><span style="color:#e1e4e8;">    &quot;input&quot;: &quot;I am anxious&quot;,</span></span>
<span class="line"><span style="color:#e1e4e8;">    &quot;output&quot;: &quot;She is anxious.&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;">}, {</span></span>
<span class="line"><span style="color:#e1e4e8;">    &quot;instruction&quot;: &quot;What are the three primary colors?&quot;,</span></span>
<span class="line"><span style="color:#e1e4e8;">    &quot;input&quot;: &quot;&quot;,</span></span>
<span class="line"><span style="color:#e1e4e8;">    &quot;output&quot;: &quot;The three primary colors are red, blue, and yellow.&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;">}</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">{</span></span>
<span class="line"><span style="color:#24292e;">    &quot;instruction&quot;: &quot;Rewrite the following sentence in the third person&quot;,</span></span>
<span class="line"><span style="color:#24292e;">    &quot;input&quot;: &quot;I am anxious&quot;,</span></span>
<span class="line"><span style="color:#24292e;">    &quot;output&quot;: &quot;She is anxious.&quot;</span></span>
<span class="line"><span style="color:#24292e;">}, {</span></span>
<span class="line"><span style="color:#24292e;">    &quot;instruction&quot;: &quot;What are the three primary colors?&quot;,</span></span>
<span class="line"><span style="color:#24292e;">    &quot;input&quot;: &quot;&quot;,</span></span>
<span class="line"><span style="color:#24292e;">    &quot;output&quot;: &quot;The three primary colors are red, blue, and yellow.&quot;</span></span>
<span class="line"><span style="color:#24292e;">}</span></span></code></pre></div><p>2、然后，基于这些指令数据使用HuggingFace Transformers框架精调LLaMA-7B模型。</p><p><img src="`+t+'" alt="图片"></p><p>代码及实践操作，请参考</p><p><a href="https://mp.weixin.qq.com/s/I4h3WXGwqEPVKbgy-BmpoA" target="_blank" rel="noreferrer">https://mp.weixin.qq.com/s/I4h3WXGwqEPVKbgy-BmpoA</a></p>',15),l=[p];function r(c,i,u,q,h,d){return e(),a("div",null,l)}const y=s(o,[["render",r]]);export{m as __pageData,y as default};
