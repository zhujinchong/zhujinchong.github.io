import{_ as e,o as a,c as i,Q as t}from"./chunks/framework.2516552c.js";const s="/assets/image-20240206095850385.7a82bfbc.png",n="/assets/image-20240206101148923.4dc9c35e.png",u=JSON.parse('{"title":"Vid2DensePose","description":"","frontmatter":{},"headers":[],"relativePath":"articles/Algorithm/14LMM/06Vid2DensePose_MagicAnimate.md","filePath":"articles/Algorithm/14LMM/06Vid2DensePose_MagicAnimate.md","lastUpdated":null}'),o={name:"articles/Algorithm/14LMM/06Vid2DensePose_MagicAnimate.md"},r=t('<h1 id="vid2densepose" tabindex="-1">Vid2DensePose <a class="header-anchor" href="#vid2densepose" aria-label="Permalink to &quot;Vid2DensePose&quot;">​</a></h1><p>Vid2DensePose 是一款功能强大的工具，旨在将 <strong>DensePose</strong> 模型应用于视频，为每个帧生成详细的“部分索引”可视化。该工具对于增强动画特别有用，特别是与 MagicAnimate 结合使用以实现时间一致的人体图像动画。</p><p><img src="'+s+'" alt="image-20240206095850385"></p><h1 id="densepose" tabindex="-1">DensePose <a class="header-anchor" href="#densepose" aria-label="Permalink to &quot;DensePose&quot;">​</a></h1><p>DensePose是Meta开源的项目，可以将 RGB 图像的所有人体像素映射到人体的 3D 表面。</p><h1 id="magicanimate" tabindex="-1">MagicAnimate <a class="header-anchor" href="#magicanimate" aria-label="Permalink to &quot;MagicAnimate&quot;">​</a></h1><p>字节开源项目，它可以从单张图片和一个动作视频中生成动画视频。（多人也是可以的）</p><p><img src="'+n+'" alt="image-20240206101148923"></p><p>是一个基于扩散模型的人类图像动画框架，意在强调时间一致性，忠实保留参考图像并提高动画的真实感，可以在推理的过程中产生平滑的视频。</p><h1 id="animateanyone" tabindex="-1">AnimateAnyone <a class="header-anchor" href="#animateanyone" aria-label="Permalink to &quot;AnimateAnyone&quot;">​</a></h1><p>阿里项目，但是没有开源。被字节秒了！</p><p>角色+动作+视频平滑控制</p><ul><li><p>referenceNet用来进行角色控制</p></li><li><p>pose guider进行动作的编码</p></li><li><p>最后使用temperal layer进行时延的训练，使得最后的图像序列在时间上保证连续性</p></li></ul>',13),c=[r];function l(p,d,m,_,h,g){return a(),i("div",null,c)}const A=e(o,[["render",l]]);export{u as __pageData,A as default};
