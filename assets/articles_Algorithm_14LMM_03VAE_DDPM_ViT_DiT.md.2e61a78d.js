import{_ as t,o as e,c as a,Q as s}from"./chunks/framework.2516552c.js";const r="/assets/v2-29563658cff776aee4fb49d84eec2741_720w.8110a765.webp",i="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAJBAMAAAD5iKAgAAAAKlBMVEX///8AAACYmJgQEBAyMjLu7u6IiIjMzMxUVFSqqqp2dnZERES6urpmZmbLiARfAAAAN0lEQVQIHWNgYDIJSGBgqJi2+gADQwDDJAYg4AQKMDAogQgmBRCpxMB+gIHHLXM1AwMXw+VWBgDsgwigMGZi5AAAAABJRU5ErkJggg==",o="/assets/v2-82ba828b4f6fb7e0a9aed4495ff407ac_720w-1708603386528.893fafc7.webp",f=JSON.parse('{"title":"VAE","description":"","frontmatter":{},"headers":[],"relativePath":"articles/Algorithm/14LMM/03VAE_DDPM_ViT_DiT.md","filePath":"articles/Algorithm/14LMM/03VAE_DDPM_ViT_DiT.md","lastUpdated":null}'),n={name:"articles/Algorithm/14LMM/03VAE_DDPM_ViT_DiT.md"},l=s('<p>主流生成模型：</p><p><img src="'+r+'" alt="img"></p><h1 id="vae" tabindex="-1">VAE <a class="header-anchor" href="#vae" aria-label="Permalink to &quot;VAE&quot;">​</a></h1><p><a href="https://blog.csdn.net/v_JULY_v/article/details/130361959?spm=1001.2014.3001.5502" target="_blank" rel="noreferrer">https://blog.csdn.net/v_JULY_v/article/details/130361959?spm=1001.2014.3001.5502</a></p><p>AE自编码器存在的问题：绝大多数的随机的潜空间z是没有任何意义的噪声。原因在于没有显性的对z的分布进行建模。</p><p>VAE(自变分编码器，Variational Autoencoders)则是在AE的基础上，<strong>显性的对<img src="'+i+'" alt="z">的分布<img src="https://latex.csdn.net/eq?p%28z%29" alt="p(images/eq.png)">进行建模</strong>(比如符合某种常见的概率分布)<strong>，使得自编码器成为一个合格的生成模型</strong>。</p><p>为了抑制自编码过程中的过拟合，VAE编码器的输出是一个正态分布，而不是一个具体的编码。VAE的损失函数除了要最小化重建图像与原图像之间的均方误差外，还要最大化每个分布和标准正态分布之间的相似度。</p><p>最终表现形式就是在目标函数Loss中加正则化：</p><p><img src="'+o+'" alt="img"></p><p>代码实现：<a href="https://www.cnblogs.com/picassooo/p/12601785.html" target="_blank" rel="noreferrer">https://www.cnblogs.com/picassooo/p/12601785.html</a></p><h1 id="ddpm" tabindex="-1">DDPM <a class="header-anchor" href="#ddpm" aria-label="Permalink to &quot;DDPM&quot;">​</a></h1><p><a href="https://blog.csdn.net/v_JULY_v/article/details/130361959?spm=1001.2014.3001.5502" target="_blank" rel="noreferrer">https://blog.csdn.net/v_JULY_v/article/details/130361959?spm=1001.2014.3001.5502</a></p><p>DDPM（Denoising Diffusion Probabilistic Models）主要有两个贡献</p><p>1、<strong>从预测转换图像改进为预测噪声</strong> (即如DiT论文所说，reformulating diffusion models to predict noise instead of pixel，可惜强调这点的文章太少了，可它是DDPM的关键，更是DDPM的本质）DDPM采用了一个U-Net 结构的Autoencoder对t时刻的高斯噪声z进行预测。</p><p>2、<strong>DDPM只预测正态分布的均值</strong>，虽然正态分布由均值和方差决定，但作者在这里发现，其实模型不需要学方差，只需要学习均值就行。逆向过程中高斯分布的方差项直接使用一个常数，模型的效果就已经很好。所以就再一次降低了模型的优化难度。</p><h1 id="detr" tabindex="-1">DETR <a class="header-anchor" href="#detr" aria-label="Permalink to &quot;DETR&quot;">​</a></h1><h1 id="vit" tabindex="-1">ViT <a class="header-anchor" href="#vit" aria-label="Permalink to &quot;ViT&quot;">​</a></h1>',17),p=[l];function c(A,_,d,g,m,h){return e(),a("div",null,p)}const M=t(n,[["render",c]]);export{f as __pageData,M as default};
