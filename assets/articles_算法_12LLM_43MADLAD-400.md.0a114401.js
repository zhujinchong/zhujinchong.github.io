import{_ as t,o as e,c as a,Q as d}from"./chunks/framework.2516552c.js";const o="/assets/image-20231018144617369.76aecfea.png",r="/assets/image-20231018144633271.fb463831.png",M=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"articles/算法/12LLM/43MADLAD-400.md","filePath":"articles/算法/12LLM/43MADLAD-400.md","lastUpdated":null}'),s={name:"articles/算法/12LLM/43MADLAD-400.md"},c=d('<p>论文：MADLAD-400: A Multilingual And Document-Level Large Audited Dataset</p><p>时间：2023.9.9</p><p>机构：google</p><p>abstract</p><p>Google DeepMind与Google Research的研究人员推出了一个全新的多语言数据集——MADLAD-400！这个数据集汇集了来自全球互联网的419种语言的大量文本数据，其规模和语言覆盖范围在公开可用的多语言数据集中应该是最大的。研究人员从Common Crawl这个庞大的网页爬虫项目中提取了大量数据，并进行了人工审核，删除了许多噪音，使数据集的质量得到了显著提升。</p><p>它的数据量非常庞大，包含了5万亿个tokens！这为训练大规模多语言模型提供了所需的海量数据。模型所训练的数据量越大，其效果就越好，这个数据集满足了对大规模数据的需求。</p><p>此外，数据集是按文档划分的，而不是简单的句子级别，这更符合语言的自然分布。研究人员还经过手动审核，对存在问题的语言数据进行了过滤，以确保数据集的整体质量。</p><p>为了验证这个数据集的质量，Google还据此训练了一个翻译模型，称为MT模型。它包含不同规模的模型：</p><table><thead><tr><th>模型规模</th><th>层次数</th><th>参数数量</th></tr></thead><tbody><tr><td>MT-3B</td><td>32</td><td>30亿</td></tr><tr><td>MT-7.2B</td><td>48</td><td>72亿</td></tr><tr><td>MT-7.2B-Finetuned</td><td>48</td><td>72亿</td></tr><tr><td>MT-10.7B</td><td>32</td><td>107亿</td></tr></tbody></table><p>Table 4: Evaluation scores on WMT (depicted as <code>&lt;bleu&gt;</code> / <code>&lt;chrf&gt;</code>) for the MT models compared against NLLB-54B.</p><p><img src="'+o+'" alt="image-20231018144617369"></p><p>Table 5: Evaluation scores on Flores-200 (depicted as <code>&lt;bleu&gt;</code> / <code>&lt;chrf&gt;</code>) for the MT models compared against NLLB-54B. All metrics are computed with the sacrebleu reference implementation.</p><p><img src="'+r+'" alt="image-20231018144633271"></p>',13),p=[c];function l(n,i,_,m,g,h){return e(),a("div",null,p)}const L=t(s,[["render",l]]);export{M as __pageData,L as default};
