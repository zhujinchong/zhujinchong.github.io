import{_ as t,o as e,c as a,Q as r}from"./chunks/framework.2516552c.js";const f=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"articles/算法/12LLM/06MTDNN.md","filePath":"articles/算法/12LLM/06MTDNN.md","lastUpdated":1698165534000}'),s={name:"articles/算法/12LLM/06MTDNN.md"},i=r('<p>2019.1.31 微软</p><p>Multi-Task Deep Neural Networks for Natural Language Understanding</p><p><a href="https://arxiv.org/abs/1901.11504" target="_blank" rel="noreferrer">https://arxiv.org/abs/1901.11504</a></p><p>思想：</p><p>两个阶段：预训练和多任务微调。预训练和BERT一样。微调阶段：将四个任务的数据打乱，随机拿出一个任务的batch训练，提高模型泛化能力。</p><p>四个独立任务：</p><ul><li>单句分类：采用[CLS]作为句子编码表示，softmax损失函数</li><li>文本相似度：采用[CLS]作为句子编码表示，sigmoid损失函数</li><li>两个句子分类：分别将第一句和第二句的词编码拼接，参考<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.03556" target="_blank" rel="noreferrer">SAN模型</a>迭代推理结果</li><li>相关性排序：采用[CLS]作为句子编码表示，sigmoid损失函数</li></ul>',7),o=[i];function l(_,p,n,c,d,h){return e(),a("div",null,o)}const m=t(s,[["render",l]]);export{f as __pageData,m as default};
