import{_ as e,o as t,c as r,Q as o}from"./chunks/framework.2516552c.js";const a="/assets/640-1572833442749.a1324b56.webp",i="/assets/640-1572835708344.8829b248.webp",p="/assets/640-1572836586081.faeafb16.webp",s="/assets/640-1572838893454.d8f96456.webp",d="/assets/v2-4c1dbed34a8f8469dc0fefe44b860edc_hd.15ace072.jpg",n="/assets/v2-477b738008eb2b5650577bbd220bc58d_hd.6032f37d.jpg",l="/assets/v2-0245d07d9e227d1cb1091d96bf499032_hd.3ead53d5.jpg",u=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"articles/算法/12LLM/04bert1进化史.md","filePath":"articles/算法/12LLM/04bert1进化史.md","lastUpdated":1698149129000}'),c={name:"articles/算法/12LLM/04bert1进化史.md"},_=o('<p>Bengio 在2003年发表在JMLR上的论文“神经网络语言模型”，英文小名NNLM。它生于2003，火于2013。</p><p><img src="'+a+'" alt="img"></p><p>任务：输入前面t-1个单词，预测第t个单词。其中输入是one-hot编码的词Wi，以后乘以矩阵Q获得向量C(Wi)。然后拼接在一起，通过隐层，接着softmax去预测。</p><p>上面任务不仅自己能够根据上文预测后接单词是什么，同时获得一个矩阵Q，该矩阵就可以获得词向量。而2013年最火的用语言模型做Word Embedding的工具是Word2Vec，之后是Glove。</p><ol><li>2013年，word2vec，固定词向量</li><li>2018年，Facebook的ELMO</li><li>2018年，OpenAI的GPT</li><li>2018年10月，Google的BERT</li></ol><h3 id="_1-word2vec" tabindex="-1">1. Word2Vec <a class="header-anchor" href="#_1-word2vec" aria-label="Permalink to &quot;1. Word2Vec&quot;">​</a></h3><p>在word2vec，每个词都有一个固定词向量表示。</p><p>缺点：一词多义</p><h3 id="_2-elmo" tabindex="-1">2. ELMO <a class="header-anchor" href="#_2-elmo" aria-label="Permalink to &quot;2. ELMO&quot;">​</a></h3><p>论文题目“Deep contextualized word representation”。</p><p>ELMO的本质思想是：我事先用语言模型学好一个单词的Word Embedding，此时多义词无法区分，不过这没关系。在我实际使用Word Embedding的时候，单词已经具备了特定的上下文了，这个时候我可以根据上下文单词的语义去调整单词的Word Embedding表示，这样经过调整后的Word Embedding更能表达在这个上下文中的具体含义，自然也就解决了多义词的问题了。所以ELMO本身是个根据当前上下文对Word Embedding动态调整的思路。</p><p>ELMO采用了典型的两阶段过程，第一个阶段是利用语言模型进行预训练；第二个阶段是在做下游任务时，从预训练网络中提取对应单词的网络各层的Word Embedding作为新特征补充到下游任务中，即特征融合。</p><p>具体怎么训练？（我还不清楚）ELMO语言模型训练目标是，根据单词上下文，预测单词，和CBOW模型很像。</p><p><img src="'+i+'" alt="img"></p><p>上图展示的是其预训练过程，网络结构采用了双层双向LSTM，输入是一个句子，句子中每个单词都能得到对应的三个Embedding。</p><p><img src="'+p+'" alt="img"></p><p>使用很简单，输入句子，将三个Embedding加权（权重可以学习）得到特征融合的词向量，词向量用于下游任务。</p><p>缺点：</p><ol><li>LSTM特征抽取能力弱与Transformer</li><li>特征融合能力没有微调好</li></ol><h3 id="_3-gpt" tabindex="-1">3. GPT <a class="header-anchor" href="#_3-gpt" aria-label="Permalink to &quot;3. GPT&quot;">​</a></h3><ol><li>GPT采取Transformer作为特征提取器</li><li>开创&quot;基于Fine-tuning的模式&quot;</li></ol><p>GPT也采用两阶段过程，第一个阶段是利用语言模型进行预训练，第二阶段通过Fine-tuning的模式解决下游任务。</p><p>GPT预训练采用单向的语言模型，即根据单词上文，预测单词。缺点就是没有使用单词下文。</p><p><img src="'+s+'" alt="img"></p><p>首先，对于不同的下游任务来说，本来你可以任意设计自己的网络结构，现在不行了，你要向GPT的网络结构看齐，把任务的网络结构改造成和GPT的网络结构是一样的。然后，在做下游任务的时候，利用第一步预训练好的参数初始化GPT的网络结构，这样通过预训练学到的语言学知识就被引入到你手头的任务里来了，这是个非常好的事情。再次，你可以用手头的任务去训练这个网络，对网络参数进行Fine-tuning，使得这个网络更适合解决手头的问题。</p><p>这里引入了一个新问题：对于NLP各种花样的不同任务，怎么改造才能靠近GPT的网络结构呢？</p><p><img src="'+d+'" alt="img"></p><p>GPT论文给了一个改造施工图如上，其实也很简单：对于分类问题，不用怎么动，加上一个起始和终结符号即可；对于句子关系判断问题，比如Entailment，两个句子中间再加个分隔符即可；对文本相似性判断问题，把两个句子顺序颠倒下做出两个输入即可，这是为了告诉模型句子顺序不重要；对于多项选择问题，则多路输入，每一路把文章和答案选项拼接作为输入即可。从上图可看出，这种改造还是很方便的，不同任务只需要在输入部分施工即可。</p><p>GPT缺点：</p><ol><li>语言模型是单向的</li><li>不太会炒作。。</li></ol><h3 id="_3-bert" tabindex="-1">3. BERT <a class="header-anchor" href="#_3-bert" aria-label="Permalink to &quot;3. BERT&quot;">​</a></h3><p>相比GPT，改进两点：1.双向语言模型；2.数据规模更大</p><p><img src="'+n+'" alt="img"></p><p>当然，它也面临着下游任务网络结构改造的问题，在改造任务方面Bert和GPT有些不同，下面简单介绍一下。</p><p><img src="'+l+'" alt="img"></p><p>对于种类如此繁多而且各具特点的下游NLP任务，Bert如何改造输入输出部分使得大部分NLP任务都可以使用Bert预训练好的模型参数呢？上图给出示例，对于句子关系类任务，很简单，和GPT类似，加上一个起始和终结符号，句子之间加个分隔符即可。对于输出来说，把第一个起始符号对应的Transformer最后一层位置上面串接一个softmax分类层即可。对于分类问题，与GPT一样，只需要增加起始和终结符号，输出部分和句子关系判断任务类似改造；对于序列标注问题，输入部分和单句分类是一样的，只需要输出部分Transformer最后一层每个单词对应位置都进行分类即可。从这里可以看出，上面列出的NLP四大任务里面，除了生成类任务外，Bert其它都覆盖到了，而且改造起来很简单直观。尽管Bert论文没有提，但是稍微动动脑子就可以想到，其实对于机器翻译或者文本摘要，聊天机器人这种生成式任务，同样可以稍作改造即可引入Bert的预训练成果。只需要附着在S2S结构上，encoder部分是个深度Transformer结构，decoder部分也是个深度Transformer结构。根据任务选择不同的预训练数据初始化encoder和decoder即可。这是相当直观的一种改造方法。当然，也可以更简单一点，比如直接在单个Transformer结构上加装隐层产生输出也是可以的。不论如何，从这里可以看出，NLP四大类任务都可以比较方便地改造成Bert能够接受的方式。这其实是Bert的非常大的优点，这意味着它几乎可以做任何NLP的下游任务，具备普适性，这是很强的。</p>',36),m=[_];function b(g,T,h,P,f,L){return t(),r("div",null,m)}const G=e(c,[["render",b]]);export{u as __pageData,G as default};
