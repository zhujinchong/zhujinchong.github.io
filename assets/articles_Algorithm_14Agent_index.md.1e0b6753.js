import{_ as e,o as a,c as t,Q as n}from"./chunks/framework.2516552c.js";const r="/assets/v2-e6f1587c8fdb7c78eaf479aa96a40d5b_720w.0757f34c.webp",o="/assets/agent-overview.4dbf69f7.png",i="/assets/image-20231106162618860.50b02d50.png",g="/assets/image-20231106164821605.c584e77b.png",s="/assets/v2-4a60a387bb03f16d4aa51975a855dde1_1440w.4ac6ec23.webp",T=JSON.parse('{"title":"引言","description":"","frontmatter":{},"headers":[],"relativePath":"articles/Algorithm/14Agent/index.md","filePath":"articles/Algorithm/14Agent/index.md","lastUpdated":null}'),l={name:"articles/Algorithm/14Agent/index.md"},p=n('<h1 id="引言" tabindex="-1">引言 <a class="header-anchor" href="#引言" aria-label="Permalink to &quot;引言&quot;">​</a></h1><p>从今年 3 月 AutoGPT 推出后，Generative Agent、GPT-Engineer、BabyAGI 项目的爆发将 LLM 地叙事代入了新的阶段。Lillian 在自己的 Twitter 中也认为“This is probably just a new era”。</p><p>2023 年 6 月，OpenAI 的 Safety 团队负责人 Lilian Weng 发布了一篇 6000 字的博客介绍 AI Agent，并认为这将使 LLM 转为通用问题解决方案的途径之一。Lilian Weng 表示 AI Agent 主要由规划（Planning）、记忆（Memory）、工具使用（Tool Use）三个核心组件构成，其核心概念是使用 LLM 解决问题，让 LLM 学会使用工具，可以大扩展其能力。</p><p>1、规划（Planning）• 子目标和分解：AI Agents 能够将大型任务分解为较小的、可管理的子目标，以便高效的处理复杂任务；• 反思和细化：Agents 可以对过去的行为进行自我批评和反省，从错误中吸取经验教训，并为接下来的行动进行分析、总结和提炼，这种反思和细化可以帮助 Agents 提高自身的智能和适应性，从而提高最终结果的质量。</p><p>2、记忆 （Memory）• 短期记忆：所有上下文学习都是依赖模型的短期记忆能力进行的；• 长期记忆：这种设计使得 AI Agents 能够长期保存和调用无限信息的能力，一般通过外部载体存储和快速检索来实现。</p><p>3、工具使用（Tool use）• AI Agents 可以学习如何调用外部 API，以获取模型权重中缺少的额外信息，这些信息通常在预训练后很难更改，包括当前信息、代码执行能力、对专有信息源的访问等。</p><p>人大高瓴 AI 学院团队在 8 月发布综述论文《A Survey on Large Language Model based Autonomous Agents》，研究者基于以往研究总结了一项 Agent 设计架构，由分析模块、记忆模块、规划模块和动作模块组成。</p><p>① 分析模块：用于识别智能体是什么角色。在现有的工作中，有三种常用的策略来生成智能体配置文件：手工制作方法、LLM-generation 方法、数据集对齐方法。</p><p>② 记忆模块：用于记忆从环境中感知到的信息，并利用记录的记忆来促进智能体未来的动作。</p><p>③ 规划模块：用于将复杂任务分解为简单的子任务，然后由智能体逐一解决。论文介绍了两种规划模块：没有反馈的规划以及有反馈的规划。</p><p>④ 动作模块：用于将智能体的决策转化为具体的结果输出。它直接与环境交互，决定智能体完成任务的有效性。</p><p>复旦 FudanNLP 团队在 9 月发布综述论文《The Rise and Potential of Large Language ModelBased Agents: A Survey》，研究者所总结的 Agent 框架则是由控制端、感知端和行动端三部分组成。</p><p>① 控制端（Brain）：通常由 LLMs 构成，是智能代理的核心。它不仅可以存储记忆和知识，还承担着信息处理、决策等不可或缺的功能。它可以呈现推理和计划的过程，并很好地应对未知任务，反映出智能代理的泛化性和迁移性。</p><p>② 感知端（Perception）：将智能代理的感知空间从纯文本拓展到包括文本、视觉和听觉等多模态领域，使代理能够更有效地从周围环境中获取与利用信息。</p><p>③ 行动端（Action）：除了常规的文本输出，还赋予代理具身能力、使用工具的能力，使其能够更好地适应环境变化，通过反馈与环境交互，甚至能够塑造环境。</p><h1 id="agent本质" tabindex="-1">Agent本质 <a class="header-anchor" href="#agent本质" aria-label="Permalink to &quot;Agent本质&quot;">​</a></h1><p><img src="'+r+'" alt="img"></p><p>本质上就是写prompt，让模型仿照你的方式来进行执行的一种应用范式，prompt里面包含一些tools的描述，然后我们可以根据模型的输出使用一些外部tools(例如计算器，搜索API，数据库，程序接口，各种模型的API)</p><p>目前有两种类型的Agents：</p><ul><li>Action agents: 在每个时间步长，使用所有先前操作的输出来决定下一个操作.</li><li>Plan-and-execute agents：预先决定完整的行动顺序，然后在不更新计划的情况下全部执行。</li></ul><p>Action Agents适合小型的任务，而plan-and-execute agents更适合需要保持长期目标的复杂任务，通常最好的方法是通过让plan-and-execute agent使用action agents来执行计划，将action agents的动态性与plan-and-execute agent的计划能力相结合。</p><h1 id="agent类型" tabindex="-1">Agent类型 <a class="header-anchor" href="#agent类型" aria-label="Permalink to &quot;Agent类型&quot;">​</a></h1><p><img src="'+o+'" alt="img"></p><p>一个Agent的基本组成应该包含如下四个方面<strong>规划</strong>（planning), <strong>工具</strong>（Tools), <strong>执行</strong>(Action), 和<strong>记忆</strong>(Memory)。</p><p>Agent Planning是Agent能力的核心，一个好的规划决定了agent能否顺利执行以及解决问题，规划简单来说就是<strong>任务分解(Task Decomposition)</strong>; 把复杂的问题划分成可以一步步解决的小步骤，以及不断根据**反馈(feedback)**去重新调整策略。</p><h2 id="chain-of-thought" tabindex="-1">Chain of thought <a class="header-anchor" href="#chain-of-thought" aria-label="Permalink to &quot;Chain of thought&quot;">​</a></h2><p><strong>Chain-of-Thought</strong>是常见用来引导模型进行任务分解的大模型<strong>提示(prompting)<strong>方法，其主要方法就是提供任务分解的</strong>少量示例(few-shot examples)</strong>，利用大模型的<strong>上下文学习能力(In-context learning)<strong>去模仿进行类似的</strong>任务分解和规划</strong>。</p><p>chain of tree也是用于任务分解和规划。</p><h2 id="self-ask" tabindex="-1">Self-ask <a class="header-anchor" href="#self-ask" aria-label="Permalink to &quot;Self-ask&quot;">​</a></h2><p>提出self ask方式的论文 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2210.03350" target="_blank" rel="noreferrer">Measuring and Narrowing the Compositionality Gap in Language Model</a> ，作者的英文介绍文 <a href="https://link.zhihu.com/?target=https%3A//ofir.io/Self-ask-prompting/" target="_blank" rel="noreferrer">Self-ask Prompting</a> 。</p><p><img src="'+i+'" alt="image-20231106162618860"></p><p>主要思路：引导LLM将一个复杂的问题拆分为简单的问题，逐个回答，然后汇总成为答案。</p><p>实施细节：</p><p>1、如上图，白色背景的是prompt，绿色背景的文本是LM的输出，下划线的是inference-time的问题。通过上文样本提示LLM输出Follow-up和immediate answer步骤。</p><p>2、拆分出的子问题，不依赖LLM自己进行回答，而是调用外部搜索工具进行回答。并把结果交给LLM继续思考推理。</p><h2 id="react-yao-et-al" tabindex="-1">ReAct(Yao et al.) <a class="header-anchor" href="#react-yao-et-al" aria-label="Permalink to &quot;ReAct(Yao et al.)&quot;">​</a></h2><p>ReAct是 Reasoning + Acting的简写，提出的论文是 <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2210.03629" target="_blank" rel="noreferrer">ReAct: Synergizing Reasoning and Acting in Language Models</a> ，一个结合Langchain的详细介绍可以见 <a href="https://link.zhihu.com/?target=https%3A//tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/" target="_blank" rel="noreferrer">https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/</a> 。</p><p>ReAct也是引导LLM将复杂的问题解决过程拆解为简单的步骤，差异是：ReAct每次让LLM输出一个当前的【思考】和【要做的动作】，这个动作并不只限于检索信息，可以是调用任何工具。</p><p><img src="'+g+'" alt="image-20231106164821605"></p><p>这样ReAct引入了外部工具的概念，让LLM能够通过这种步进式的方式逐步思考并调用外部工具，根绝外部工具的结果进一步思考循环。同时也可以仅仅是输出一步思考，并继续下去，类似CoT。</p><p>这个过程仍然是靠few-shot的方式给例子，引导LLM类似的“思考”，并按格式返回后续步骤的信息。（上图没给few-shot，Langchain中用的是Few-shot方式）</p><h2 id="rewoo-binfeng-xu-et-al" tabindex="-1">ReWoo(Binfeng Xu et al.) <a class="header-anchor" href="#rewoo-binfeng-xu-et-al" aria-label="Permalink to &quot;ReWoo(Binfeng Xu et al.)&quot;">​</a></h2><p><img src="'+s+'" alt="img"></p><p><strong>ReWOO</strong>是类似在ReACT架构基础上，去掉了观察（observation)这个模块，取而代之的是把整个planning过程划分成**&#39;Planner&#39;, &#39;Worker&#39;<strong>和</strong>&#39;Slover**&#39;分别去进行规划、执行和总结三个部分，在API消耗和精度上都有所提升。</p><h1 id="几个重要的agent" tabindex="-1">几个重要的Agent <a class="header-anchor" href="#几个重要的agent" aria-label="Permalink to &quot;几个重要的Agent&quot;">​</a></h1><h2 id="autogpt" tabindex="-1">AutoGPT <a class="header-anchor" href="#autogpt" aria-label="Permalink to &quot;AutoGPT&quot;">​</a></h2><p>时间：2023.03</p><p>2023年3月，开发人员Significant Ggravitas在GitHub上发布了开源项目AutoGPT，它以GPT-4为驱动基础，允许AI自主行动，完全无需用户提示每个操作。给AutoGPT提出目标，它就能够自主去分解任务、执行操作、完成任务。作为GPT-4完全自主运行的最早示例之一，AutoGPT迅速走红于AI界，并带动了整个AIAgent领域的研究与发展，它也成为了GitHub排行榜4月增长趋势第一名。截至2023年8月15日，AutoGPT在GitHub上已经得到了超过14.7万颗star。</p><p>基于GPT-4的强大能力和AutoGPT带来的Agent热潮，开发者们很快便基于AutoGPT实现了很多有趣的应用案例，例如自动实现代码debug、自主根据财经网站信息进行投资挣钱、自主完成复杂网站建设、进行科技产品研究并生成报告等。</p><p>AutoGPT采用的是GPT-3.5和GPT-4的API，成本高；</p><p>正常使用中经常出现需要拆分出几十上百个step的任务，响应慢；</p><p>遇到GPT-4无法解决的step问题时，就会陷入死循环中。</p><h2 id="agentgpt" tabindex="-1">AgentGPT <a class="header-anchor" href="#agentgpt" aria-label="Permalink to &quot;AgentGPT&quot;">​</a></h2><p>AutoGPT的网页版本——AgentGPT，仅需给定大模型的API即可实现网页端的AIAgent。</p><h2 id="jarvis-hugginggpt" tabindex="-1"><strong>JARVIS</strong> / HuggingGPT <a class="header-anchor" href="#jarvis-hugginggpt" aria-label="Permalink to &quot;**JARVIS** / HuggingGPT&quot;">​</a></h2><p>将模型社区HuggingFace和ChatGPT连接在一起，形成了一个AIAgent。2023年4月，浙江大学和微软联合团队发布了HuggingGPT，它可以连接不同的AI模型，以解决用户提出的任务。HuggingGPT融合了HuggingFace中成百上千的模型和GPT，可以解决24种任务，包括文本分类、对象检测、语义分割、图像生成、问答、文本语音转换和文本视频转换。具体步骤分为四步：1)任务规划：使用ChatGPT来获取用户请求；2)模型选择：根据HuggingFace中的函数描述选择模型，并用选中的模型执行AI任务；3)任务执行：使用第2步选择的模型执行的任务，总结成回答返回给ChatGPT；4)回答生成：使用ChatGPT融合所有模型的推理，生成回答返回给用户</p><h2 id="babyagi" tabindex="-1">BabyAGI <a class="header-anchor" href="#babyagi" aria-label="Permalink to &quot;BabyAGI&quot;">​</a></h2><p>基于人工智能的任务管理系统。该系统使用OpenAI和Pinecone API来创建、优先排序和执行任务。该系统的主要思想是根据先前任务的结果和预定义的目标创建任务。</p><h1 id="其他agent" tabindex="-1">其他Agent <a class="header-anchor" href="#其他agent" aria-label="Permalink to &quot;其他Agent&quot;">​</a></h1><h2 id="qwen-agent" tabindex="-1">Qwen Agent <a class="header-anchor" href="#qwen-agent" aria-label="Permalink to &quot;Qwen Agent&quot;">​</a></h2><ul><li>与 Qwen 讨论当前网页或 PDF 文档。</li><li>快速理解多个web页面的内容，总结浏览内容，消除繁琐的写作任务。</li><li>支持插件集成，包括用于数学问题解决和数据可视化的代码解释器。</li><li>支持的文件包括（pdf和csv文件），基于csv文件可以做智能图表的问答。</li></ul><h2 id="lagent" tabindex="-1">Lagent <a class="header-anchor" href="#lagent" aria-label="Permalink to &quot;Lagent&quot;">​</a></h2><ul><li><strong>支持高性能推理.</strong> 我们现在支持了高性能推理 <a href="https://github.com/InternLM/lmdeploy/tree/main" target="_blank" rel="noreferrer">lmdeploy turbomind</a>.</li><li><strong>实现了多种类型的智能体，</strong> 我们支持了经典的 <a href="https://arxiv.org/abs/2210.03629" target="_blank" rel="noreferrer">ReAct</a>，<a href="https://github.com/Significant-Gravitas/Auto-GPT" target="_blank" rel="noreferrer">AutoGPT</a> 和 <a href="https://arxiv.org/abs/2305.18323" target="_blank" rel="noreferrer">ReWoo</a> 等智能体，这些智能体能够调用大语言模型进行多轮的推理和工具调用。</li><li><strong>框架简单易拓展.</strong> 框架的代码结构清晰且简单，只需要不到20行代码你就能够创造出一个你自己的智能体（agent）。同时我们支持了 Python 解释器、API 调用和搜索三类常用典型工具。</li><li><strong>灵活支持多个大语言模型.</strong> 我们提供了多种大语言模型支持，包括 InternLM、Llama-2 等开源模型和 GPT-4/3.5 等基于 API 的闭源模型。</li></ul>',63),h=[p];function c(A,u,d,m,f,b){return a(),t("div",null,h)}const _=e(l,[["render",c]]);export{T as __pageData,_ as default};
