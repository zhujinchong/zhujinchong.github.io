import{_ as e,o as a,c as n,k as t,a as s}from"./chunks/framework.2516552c.js";const b=JSON.parse('{"title":"如何加速","description":"","frontmatter":{},"headers":[],"relativePath":"articles/Algorithm/21模型部署/12QwenLLM.md","filePath":"articles/Algorithm/21模型部署/12QwenLLM.md","lastUpdated":null}'),o={name:"articles/Algorithm/21模型部署/12QwenLLM.md"},l=t("h1",{id:"如何加速",tabindex:"-1"},[s("如何加速 "),t("a",{class:"header-anchor",href:"#如何加速","aria-label":'Permalink to "如何加速"'},"​")],-1),c=t("p",null,"1、batch推理",-1),i=t("p",null,"2、flash-attention（fp16或bf16）",-1),r=t("p",null,"2、kv cache缓存",-1),_=t("p",null,"3、模型量化：用AutoGPTQ技术，得到BF16, Int8和Int4模型",-1),h=t("p",null,"4、多卡推理：vLLM和FastChat",-1),d=t("p",null,"注意：KV Cache和FlashAttention不能同时用，同时开启时，FlashAttention关闭。",-1),p=t("p",null,"推荐：KV",-1),u=[l,c,i,r,_,h,d,p];function m(f,L,A,k,x,M){return a(),n("div",null,u)}const g=e(o,[["render",m]]);export{b as __pageData,g as default};
