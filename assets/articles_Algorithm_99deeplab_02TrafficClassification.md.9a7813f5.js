import{_ as e,o as a,c as p,Q as t}from"./chunks/framework.2516552c.js";const r="/assets/wps1.da5cd596.jpg",o="/assets/wps2.6708eefb.jpg",n="/assets/wps4.e0a13b0a.jpg",i="/assets/wps3.8438c222.jpg",b=JSON.parse('{"title":"加密流量识别方法","description":"","frontmatter":{},"headers":[],"relativePath":"articles/Algorithm/99deeplab/02TrafficClassification.md","filePath":"articles/Algorithm/99deeplab/02TrafficClassification.md","lastUpdated":null}'),s={name:"articles/Algorithm/99deeplab/02TrafficClassification.md"},c=t('<h1 id="加密流量识别方法" tabindex="-1">加密流量识别方法 <a class="header-anchor" href="#加密流量识别方法" aria-label="Permalink to &quot;加密流量识别方法&quot;">​</a></h1><h2 id="按方法分类" tabindex="-1">按方法分类 <a class="header-anchor" href="#按方法分类" aria-label="Permalink to &quot;按方法分类&quot;">​</a></h2><p><strong>基于端口（port）的流量分类：</strong></p><p>优点：简单。</p><p>缺点：该方法的准确性一直在下降，因为较新的应用程序要么使用众所周知的端口号来掩盖其流量，要么不使用标准的注册端口号。</p><p>**基于有效载荷或数据包检验（data packet inspection：DPI）：**用于检查数据包的实际内容，而不仅仅是报头信息。基于已知的攻击特征或恶意文件的特征进行匹配。如正则表达式匹配、特征匹配、深度包检查等。</p><p>优点：简单快速，只需要检测网络流的前几个数据包。</p><p>缺点：方法仅适用于未加密的流量，且计算开销较大。</p><p>**基于流量统计特征：**这种方法通常关注网络流量的统计信息，如流量的大小、方向、持续时间、包的数量、传输速率等。</p><p>优点：可以用于加密流量，不需解密；轻量级、实时性。</p><p>缺点：依赖于人类的特征提取工程，有限精度、易受欺骗。</p><p><strong>基于深度学习方法：</strong></p><p>优点：深度学习可以通过训练自动选择特征，消除领域专家选择特征的需要，并且具有相当高的学习能力，因此可以学习高度复杂的模式，能够学习原始输入和相应输出之间的非线性关系，而不需要将问题分解为特征选择和分类的小子问题。</p><p>缺点：黑盒子，可解释性弱。</p><h2 id="按数据分类" tabindex="-1">按数据分类 <a class="header-anchor" href="#按数据分类" aria-label="Permalink to &quot;按数据分类&quot;">​</a></h2><p>流量的形式在网络传输中是二进制的比特流形式，主要构造单元有数据包和会话流。其中数据包为传输最小完整单元（Packet-Based）；会话流由通信的设备两端的一个完整交互单元，由多个数据包组成（Flow-Based）。有的论文会分为：Packet-Based、Flow-Based、Session-Based。Flow-Based只包含单向数据流，Session-Based是双向数据流。</p><p><strong>基于数据包的方法：</strong></p><p>直接将数据包的字节作为输入，包括报头信息与有效载荷。基于包的方法只关注少数包的详细信息，缺乏对全局特征的关注。如：Deep Packet</p><p><strong>基于会话流的方法：</strong></p><p>基于特征分类，机器学习、深度学习都适合。</p><p>对流中的包长进行特征提取用于分类（FS-Net）。</p><p>对流中连续的几个报文进行分类（1D-CNN）。</p><p>同时使用CNN与RNN分别提取流量的空间特征与时间特征（耗时）。</p><p>ET-BERT: 预训练是flow-based，微调flow-based, packet-based都可以！</p><h1 id="_1d-cnn" tabindex="-1">1D-CNN <a class="header-anchor" href="#_1d-cnn" aria-label="Permalink to &quot;1D-CNN&quot;">​</a></h1><p>论文：End-to-end Encrypted Traffic Classification with One-dimensional Convolution Neural Networks</p><p>时间：2017</p><p>网络流量划分粒度：</p><p>packet级：单个数据流</p><p>Flow级：一个会话中的单向数据流的集合，即同一方向的packet。</p><p>Session级：会话中所有数据流，双向的。</p><p>数据流从哪层取得：</p><p>ALL表示使用了所有层的包层选择</p><p>L7表示仅仅使用了OSI模型的第七层（应用层）的包层选择</p><p>ISCX-VPN-NonVPN-2016中的数据：</p><p>12分类：应用级分类，即所有数据。</p><p>2分类，协议封装的流量标识，即VPN vs nonVPN。</p><p>6分类：常规加密流量分类 / 协议封装的流量分类，分别有6个APP。</p><p>训练数据：数据是清理后的，取流或者会话的前n个字节作为模型输入，n取784（28*28）</p><p>实验和实验结果：</p><p><img src="'+r+'" alt="img"></p><p>对比方法：C4.5</p><p><img src="'+o+'" alt="img"></p><h1 id="deep-packet" tabindex="-1">Deep-Packet <a class="header-anchor" href="#deep-packet" aria-label="Permalink to &quot;Deep-Packet&quot;">​</a></h1><p>论文：Deep Packet: A Novel Approach For Encrypted Traffic Classification Using Deep Learning</p><p><a href="https://paperswithcode.com/paper/deep-packet-a-novel-approach-for-encrypted" target="_blank" rel="noreferrer">Deep Packet: A Novel Approach For Encrypted Traffic Classification Using Deep Learning | Papers With Code</a></p><p>时间：2018</p><p><img src="'+n+'" alt="img"></p><p>数据集：ISCX VPN-nonVPN：该数据集实在数据链路层捕获的，因此，每个数据包都包含一个以太网报头、一个IP数据报报头、一个TCP/UDP报头。</p><p>预处理：</p><p>1.删除以太网报头</p><p>2.将UDP报头填充0至20字节长度（TCP通常具有20字节长度的报头，而UDP具有8字节长度的报头。为了使传输层的段一致，在UDP段的报头末尾注入0，使它们的长度与TCP报头相等）</p><p>3.屏蔽IP数据报报头的IP</p><p>4.删除不相关的数据包，例如没有负载的数据包（TCP握手时SYN、ACK设置为1以及FIN设置为1的数据包）或者DNS数据段（将url转为IP地址的）</p><p>5.将原始数据包转为字节向量</p><p>6.截断超过1500的向量，不足1500长度的填充0</p><p>7.将向量的每个元素除以255来规范化字节向量</p><p>8.针对样本不均衡问题，对样本更多的类进行欠采样，直到类相对平衡。</p><h1 id="fs-net" tabindex="-1">FS-Net <a class="header-anchor" href="#fs-net" aria-label="Permalink to &quot;FS-Net&quot;">​</a></h1><p>论文：FS-Net: A Flow Sequence Network For Encrypted Traffic Classification</p><p>时间：2019</p><p>分类特征：Flow级的特征（特征是每个数据流的长度）</p><p>数据集：自己收集的，不公开数据。</p><p>实验结果+对比方法：</p><p><img src="'+i+'" alt="img"></p><h1 id="cnn-rnn-rf" tabindex="-1">CNN+RNN+RF <a class="header-anchor" href="#cnn-rnn-rf" aria-label="Permalink to &quot;CNN+RNN+RF&quot;">​</a></h1><p>论文：Deep Learning for Network Traffic Classification</p><p><a href="https://paperswithcode.com/paper/deep-learning-for-network-traffic" target="_blank" rel="noreferrer">Deep Learning for Network Traffic Classification | Papers With Code</a></p><p>时间：2021</p><p>方法：CNN+RNN+随机森林</p><p>深度学习CNN+RNN：用包</p><p>机器学习RF：用特征</p><h1 id="et-bert" tabindex="-1">ET-BERT <a class="header-anchor" href="#et-bert" aria-label="Permalink to &quot;ET-BERT&quot;">​</a></h1><p>论文：ET-BERT: A Contextualized Datagram Representation with Pre-training Transformers for Encrypted Traffic Classification</p><p>时间：2022-02</p><p>该方法主要分为三个部分：A. 预处理和编码加密流量为 token 组成的 BURST 结构，B. 预训练学习加密流量报文的关联关系，C. 将预训练模型应用到下游任务中微调。</p><p>BURST 结构：Flow-Based级别数据流，转成16进制后，4个一组作为token。</p><p>预训练：类似于BERT，通过掩码 BURST 预测任务（Masked BURST Model）和同源 BURST 预测任务（Same-origin BURST Prediction）学习。</p><p>微调：包括包级别和流级别。</p><h1 id="tfe-gnn" tabindex="-1">TFE-GNN <a class="header-anchor" href="#tfe-gnn" aria-label="Permalink to &quot;TFE-GNN&quot;">​</a></h1><p>论文：</p><p>时间：2023-07</p><p>背景：</p><p>1、ET-BERT只学习flow-level features，如果flows较短效果不好。</p><p>2、本文提出byte-level流量图方法。</p><h1 id="cle-tfe" tabindex="-1">CLE-TFE <a class="header-anchor" href="#cle-tfe" aria-label="Permalink to &quot;CLE-TFE&quot;">​</a></h1><p>论文：One Train for Two Tasks: An Encrypted Traffic Classification Framework Using Supervised Contrastive Learning</p><p>时间：2024-02</p><p>方法：对比学习+图神经网络</p><p>背景：</p><p>1、ET-BERT直接学习统计特征或原始字节的表示，没有考虑不同样本特征之间的潜在共性，因此不能充分揭示数据中包含的语义不变信息。</p><p>2、对比学习更能学习到高层语义。</p><h1 id="参考" tabindex="-1">参考 <a class="header-anchor" href="#参考" aria-label="Permalink to &quot;参考&quot;">​</a></h1><p>加密流量分类专题博客：</p><p><a href="https://blog.csdn.net/qq_45125356/category_11988781.html" target="_blank" rel="noreferrer">https://blog.csdn.net/qq_45125356/category_11988781.html</a></p><p>代码：</p><p>1D-CNN: <a href="https://blog.csdn.net/qq_45125356/article/details/126956497" target="_blank" rel="noreferrer">https://blog.csdn.net/qq_45125356/article/details/126956497</a></p><p>FS-Net(没有数据集): <a href="https://github.com/WSPTTH/FS-Net" target="_blank" rel="noreferrer">https://github.com/WSPTTH/FS-Net</a></p><p>Deep-Packet: <a href="https://blog.munhou.com/2020/04/05/Pytorch-Implementation-of-Deep-Packet-A-Novel-Approach-For-Encrypted-Tra%EF%AC%83c-Classi%EF%AC%81cation-Using-Deep-Learning/" target="_blank" rel="noreferrer">https://blog.munhou.com/2020/04/05/Pytorch-Implementation-of-Deep-Packet-A-Novel-Approach-For-Encrypted-Tra%EF%AC%83c-Classi%EF%AC%81cation-Using-Deep-Learning/</a></p><p>ET-BERT（代码有问题）: <a href="https://github.com/linwhitehat/ET-BERT" target="_blank" rel="noreferrer">https://github.com/linwhitehat/ET-BERT</a></p><p>ET-BERT复现（代码可用）：<a href="https://gitee.com/xxdxxdxxd/et-bert/tree/master" target="_blank" rel="noreferrer">https://gitee.com/xxdxxdxxd/et-bert/tree/master</a></p>',101),l=[c];function h(d,f,g,T,N,m){return a(),p("div",null,l)}const _=e(s,[["render",h]]);export{b as __pageData,_ as default};
