import{_ as p,o as n,c as e,k as s,a,Q as l}from"./chunks/framework.2516552c.js";const o="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHsAAAAjCAYAAAC0GnXlAAAKPUlEQVR4nO2bf0yTdx7HX7uY1kwLCQ82WxsXHzauNYHigmV3KRuBGoZ4KmxDzQbq1GWHzOG8HTp1Yyebd3qO2TnHPIGbwmWH5ILMO+CWFc8b3U2rmVSSPs12PIvmqTttl2DHxTZb7v6gyK8CIjh2Z1//kPb7+X4/z9P39/v5fL7f5+Guz75y/ocodwQ/mu4LiPL9ERX7DiIq9jTjdzTymyfNPPjTeqRIBpccVBbX4uodexyl6TVerPEQGsMmKvY0I1iySJkFwlIDCSNavbTuqmFOyTpMs8YeR59fjPXTUg47Rpc7KvZ00yPReUJg0U+MqIY1hRzNHPxuBVlJNzOQgHXtcppq2lFGsZgxuSuNMmm+8PARfmLer6XuUx9NXQZ2/74QoxokRy1idjP6ftteDw0VzQTuDtByWU1KLAROQV7zTtK1oFq4kNzHG3FdzkF/70hX0ZU9zSjus/jFArbsKaXoaQsJ7Y04JQAv3ecEjHPjb9hKR2z48jez4TED6qZu9PdpON97jUB/PlfrScg4ieKN7Csq9rTiRzrtRFiaSVoccFHGrs3BYOxr850C9eyB4J7w1B6eeUiFX/YgadNJ21jKR669LBb7LdSoY6Db64/oLSr2tOJFahRIS05ABbgczQhLTdx/PXKRpYrVoAIUdxtClogeCPWOVX8PJSr2dCJ340JHSqIAQScfvweLLNCyrh4JAX2un+A3N4xpWGLmZ5X1nPkQ9MnzEIJODq8+NmjLFiR4TUAfp4noLir2NBKSPZwR00kxAuoY4hPBXd+MsjYHIzr0RpAuDSRgdawOo/wlSlIm/k8/oHrHB8RsX4Gx3yCo0H3KRELC8Lq+j7uiZ+M/XEKOKnJrRI7U5gxU5OPYP1YjcmgU++jK/gGjsiznuev1tHfdjHWAjxud5JVkjToxomL/oNGRt6cYxVaLFBzbUmmyYU/eyurUyCEcomH8jiJ6gjZlBJAdEldHa56dwIIUARXw4D3mKfP62VfOQZ9CuCp30rJgK9uyhBG2U7OyewOE1BpU0zR1Qj0BCO9B/z8I4dr7c1oW2NiWHXkbNSrBC1QvqSH+8H7yxKFNk87ZoXO1bNrcTPc4OeW28kUjmx5vjPyI8H8RuZXDTWZyMyYoNIA6mcUb4O3GCyOaJrcWe528/ZwLa91+jOM8grudqFLX8UL2Op7bNY+WV8y3b4X3emjYYaP9ko9/fg7znyhl2yuWm9oWjcq3Xuy7q+iYvZB4uRnybeT5HbiXFmBU95kE2m1sP9iJrDaSfh/oRTUffQiLLEGUmfFgd6F/ZS9FKX13rn8ok/s3O3GVJWMa5GpSK1s6YsOZ/RTWByYzytRgLCji4XdsNNzUNuVWCNBRYUPJr+DQn47RVJWJ753NrNnhIHDLY/qxv7CON2cs46W1MfgavbguXkZxn2R+gj48af10NPmw5qegdH2JWFhG0TIDcxytdOoK2bZxOSlxDo6ckgeG1ekwIKFcHurt1sUOOrG/C+ZsI7cQbKaeuIVY13qo/HBk+JoSrpyl5T0ndTUdKIDGspyVGeCvaabj8ri9I9PVSnWjmrwlZlRxmZR/1cahtQL+S6CZFV7WCFhfexljrxOSHiU9CfD7UDBhzdABXrpPwHztIBXUM4nBhXJlqLvxw3iPh4byGmSdSLDLQ8r2/eQZga4LNF0x8tL8YVL3emjY0YgSd42OTj35lgDdF68hfW1h39Hl44Q8L/YXqzjudRLK2MqKf7XSgQin2/AVvEbJd80c7dagPt+Kd8lvObAxeVDI1iCmZsKhTqQtyQNHiFOFdh5pq8yo79MxE+h/wgQ+rvUAEZ4fj4f/cxeS1kLJvLHtVLE+5NMehIUJ6AHF7UISTYj3Al2ddJBMXlI8gSBo1KOPM47YAezlhRz/cT3vb1TRsKSWJodMnlHEf1HCn2Rkzqyh9h0VVYQ27GVLkoeYe9ZxRLeXlxL3cLw9HrkH9LGjews5mjmqW8Ez2jY2lddharBRnqHBVVnLmm2/RLOvildfFwk0KSwqbuXMmmTSB/mfo9VDlxdfDzDcT9BDa40T39g3DMRjXpMToQYRydv/Dnn9H3slOk+AkL2YFHG47c2hidMDGuLD1xo6V09ldxa5iRDoHVTxBhXcLQKLCucBIRT3SYSsvoUjOdqQUnPQuyv4tbyZ3UsFCF7nGkYSYob6G0dsL3I7SO1VVKpzSH+jjcMP9O3fFPkkYEI1eCZ96yOY+BS5SSq44qMbWJBlwmqxcShbR9oYQgMEiCc/A3x7QVi7ntUZGiDE9W+A1EJWF4qogKtXvJBkIn6YIKrZGsCJfAnSh/tSG1i80TD2Bdw0IVyHamhILeDA6wOF1ERRZRSwL3sn1W/pWKx24ew1s/JZHaqWTDo+VwBdn6H8JZ1aE6tEDSAjnxZYsFZEA+gTTeiDn9DgyKRkT3hv7fXi0ZpYNGwSjiO2gZUHiuksP0bdDgd1WCj/x8j928BoItb1fY0ht4tWktmSKIBWIE07/s0LlgLyehz85hQsWNVfC8h4/g7GRwzhFOBFavdgzN0a4QW97welqYJX3VkcqSvEFDeZkXRY99ViBSAn/BdYaCG94iyuMjOmGYCxgCOugnCjyMq/tLEy/EmTVcafs4Zd3+mTKIXrR6SyMcQOITUew/mdmd1/W4f6dBVrljcjyQEQNQjayKdA/q4LXJ+bTEByQpIZw1wAmY7GEGkFhvG3RZKLhv5JAnBJprMLjFvC4stOWk8ZMD+vo7upDbKHh9x4NJG2gd/K2H/nYJQ3dob0jxzG+1CaXmbXWQtv7M9BnOXHvq0GSsuw3kLOHhVxMUVPLKOlvRDTRA9V8NBep6Hk3eQRv/XoYn/toGFTPd7nDeQBqlkaSM0iPVyQxWjn9eXHXqD/h+msZeWjVeh/VUFuuwdiC5gTC6FTH1B3OYc0gKCH4+U1dC4opnzVyBAhnXcMmiQQcLuwY6E87Fc6UcWZpMWsj3VSfTBISf5AX79XBq2O+EirbYaIdeMtJtcwoXO1bH9DQ/4egavnnVwNemg9q2bF3ZMaNgIq0n5hw7PZhj155wQmUgjXW/VcLS2maO7I1tHFjrOw8nUzb579hON7T9LpVbN6dzHpYceaRANpNKNcghvxQivysGgm6HagZJeSV/dXju7ywL8NvPByeFVf9yG1nOT4e/FYl5YNKbAggOL2YHqklPnhnKt84UDILsQYTl8JlhWkVXdQVx3Eun0zg+W7KjsRMrbe6Dul9DiofLoK1xVwPd448H1qGSW3w98sA0WHd06wkwrT8xVDDlIGM4mzcS/Hn1yOfVkzB1bpJty39Zl6NPvKRhZSt4yHukWluEv/0FeRRhnBJE7QdOQ+W4i7un3iZ9KyE/tM85SuwNA5By3qFayK8LQnSh+TOi5VZRRTmdvOwT+OX/YM4Md+0EHKsxamThYPDbtd5O4pHPffZO5kpuARp5eOXfUEisoGvb/8/SLX27DPLWBDxkTTyZ1F9E2VO4joO2h3EP8FPTehjn5xMpoAAAAASUVORK5CYII=",t="/assets/1569411259265.da957d28.png",V=JSON.parse('{"title":"1. 原理","description":"","frontmatter":{},"headers":[],"relativePath":"articles/算法/12机器学习笔记/12bagging和随机森林.md","filePath":"articles/算法/12机器学习笔记/12bagging和随机森林.md","lastUpdated":null}'),i={name:"articles/算法/12机器学习笔记/12bagging和随机森林.md"},r=s("h1",{id:"_1-原理",tabindex:"-1"},[a("1. 原理 "),s("a",{class:"header-anchor",href:"#_1-原理","aria-label":'Permalink to "1. 原理"'},"​")],-1),c=s("blockquote",null,[s("p",null,"bagging是并联，各个学习器独立，并且有放回采样。个体学习器一般采用神经网络或者决策树。")],-1),m=s("p",null,"袋外数据：",-1),d={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},y={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.798ex"},xmlns:"http://www.w3.org/2000/svg",width:"9.65ex",height:"2.755ex",role:"img",focusable:"false",viewBox:"0 -864.9 4265.1 1217.7","aria-hidden":"true"},T=l('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(389,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1111.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(2111.4,0)"><g data-mml-node="mn" transform="translate(353.6,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(220,-345) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><rect width="820.8" height="60" x="120" y="220"></rect></g><g data-mml-node="msup" transform="translate(3172.3,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(422,363) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g></g></g>',1),_=[T],h=s("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("mfrac",null,[s("mn",null,"1"),s("mi",null,"m")]),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mi",null,"m")])])],-1),g=l('<h1 id="_2-随机森林" tabindex="-1">2. 随机森林 <a class="header-anchor" href="#_2-随机森林" aria-label="Permalink to &quot;2. 随机森林&quot;">​</a></h1><p>特点：</p><ol><li>Random Forest使用了CART决策树作为弱学习器；</li><li>决策树每个节点会选择最优的特征，但是RF会随机选择一部分特征，从这一部分特征里面选择最优的特征，增加了模型泛化性能</li></ol><p>随机森林的推广：</p><h3 id="_2-1-extra-trees" tabindex="-1">2.1 extra trees <a class="header-anchor" href="#_2-1-extra-trees" aria-label="Permalink to &quot;2.1 extra trees&quot;">​</a></h3><p>和随机森林区别：</p><ol><li>不采样，每次使用原始训练集；</li><li>在选定划分特征后，会随机选择一个特征值来划分。</li></ol><p>特点：</p><ol><li>生成决策树的规模一般不会大于RF；</li><li>方差减小，偏差增大；</li><li>泛化性能比RF更好。</li></ol><h3 id="_2-2-isolation-forest" tabindex="-1">2.2 Isolation Forest <a class="header-anchor" href="#_2-2-isolation-forest" aria-label="Permalink to &quot;2.2 Isolation Forest&quot;">​</a></h3><p>检测异常点</p><ol><li>采样个数要少</li><li>随机选择特征，随机选择特征值</li><li>深度要小</li></ol><p>对于样本点x，计算在每颗决策树上该样本的叶子节点的深度ht(x)，计算出平均深度h(x)。此时用一下公式计算x的异常概率：</p><p><img src="'+o+'" alt="1569410919936"></p><p>其中，m是样本个数，c(m)是表达式为：</p><p><img src="'+t+`" alt="1569411259265"></p><p>s(x,m)的取值在[0,1]，越接近1，异常概率越大。</p><h1 id="_3-随机森林优缺点" tabindex="-1">3. 随机森林优缺点 <a class="header-anchor" href="#_3-随机森林优缺点" aria-label="Permalink to &quot;3. 随机森林优缺点&quot;">​</a></h1><p>优点：</p><ol><li>训练可以高度并行化</li><li>特征维度很高时，仍然能高效的训练模型</li><li>采用了随机采样，训练模型方差小，泛化能力强</li><li>对部分特征缺失不敏感</li></ol><p>缺点：</p><ol><li>在某些噪音比较大的样本集上，RF模型容易陷入过拟合。</li><li>取值划分比较多的特征容易对RF的决策产生更大的影响，从而影响拟合的模型的效果。</li></ol><h1 id="调参" tabindex="-1">调参 <a class="header-anchor" href="#调参" aria-label="Permalink to &quot;调参&quot;">​</a></h1><p>库：ensemble</p><p>方法：RandomForestClassifier 和 RandomForestRegression</p><p>bagging一般参数：</p><ul><li>n_estimators：若学习器个数，默认100</li><li>oob_socre：是否采用袋外数据来评估模型好坏，默认False，建议True</li><li>criterioin：划分特征的标准，分类默认gini，回归默认mse(均方差)</li></ul><p>RF决策树参数：</p><ul><li><p>max_features：划分时考虑的最大特征数，默认auto和sqrt相似，还有&quot;log2&quot;。</p></li><li><p>max_depth：最大深度，默认不限制，如果样本多，常取10-100</p></li><li><p>min_samples_split：划分节点所需最小样本数，默认2</p></li><li><p>min_samples_leaf：叶子结点最少样本数，默认1</p></li><li><p>max_leaf_nodes：最大叶子节点数，默认“None&quot;，防止过拟合，特征多的话可以选择</p></li><li><p>min_weight_fraction_leaf：叶子节点最小的样本权重和，默认不考虑，当类别偏差大时再设置。</p></li><li></li></ul><p>代码：</p><p>数据集（直接下载）：</p><p><a href="http://files.cnblogs.com/files/pinard/train_modified.zip" target="_blank" rel="noreferrer">http://files.cnblogs.com/files/pinard/train_modified.zip</a></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">import pandas as pd</span></span>
<span class="line"><span style="color:#e1e4e8;">import numpy as np</span></span>
<span class="line"><span style="color:#e1e4e8;">import matplotlib.pyplot as plt</span></span>
<span class="line"><span style="color:#e1e4e8;">from sklearn.ensemble import RandomForestClassifier</span></span>
<span class="line"><span style="color:#e1e4e8;">from sklearn.model_selection import GridSearchCV</span></span>
<span class="line"><span style="color:#e1e4e8;">from sklearn.model_selection import cross_val_predict</span></span>
<span class="line"><span style="color:#e1e4e8;">from sklearn import metrics</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># 数据</span></span>
<span class="line"><span style="color:#e1e4e8;">train = pd.read_csv(&#39;train_modified.csv&#39;)</span></span>
<span class="line"><span style="color:#e1e4e8;">target=&#39;Disbursed&#39; # Disbursed的值就是二元分类的输出</span></span>
<span class="line"><span style="color:#e1e4e8;">IDcol = &#39;ID&#39;</span></span>
<span class="line"><span style="color:#e1e4e8;">train[&#39;Disbursed&#39;].value_counts() </span></span>
<span class="line"><span style="color:#e1e4e8;">x_columns = [x for x in train.columns if x not in [target, IDcol]]</span></span>
<span class="line"><span style="color:#e1e4e8;">X = train[x_columns]</span></span>
<span class="line"><span style="color:#e1e4e8;">y = train[&#39;Disbursed&#39;]</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># 网格搜索</span></span>
<span class="line"><span style="color:#e1e4e8;"># grid = GridSearchCV(estimator=RandomForestClassifier(n_estimators=60, </span></span>
<span class="line"><span style="color:#e1e4e8;">#                                                      max_depth = 13,</span></span>
<span class="line"><span style="color:#e1e4e8;">#                                                      min_samples_split=120, </span></span>
<span class="line"><span style="color:#e1e4e8;">#                                                      min_samples_leaf=20,</span></span>
<span class="line"><span style="color:#e1e4e8;">#                                                      random_state=10),</span></span>
<span class="line"><span style="color:#e1e4e8;">#                    param_grid={</span></span>
<span class="line"><span style="color:#e1e4e8;"># #                        &#39;n_estimators&#39;: range(10, 71, 10),</span></span>
<span class="line"><span style="color:#e1e4e8;">                       </span></span>
<span class="line"><span style="color:#e1e4e8;"># #                        &#39;max_depth&#39;: range(3, 14, 2),  </span></span>
<span class="line"><span style="color:#e1e4e8;"># #                        &#39;min_samples_split&#39;: range(50, 201, 20),</span></span>
<span class="line"><span style="color:#e1e4e8;">                       </span></span>
<span class="line"><span style="color:#e1e4e8;"># #                        &#39;min_samples_split&#39;: range(80, 150, 20),</span></span>
<span class="line"><span style="color:#e1e4e8;"># #                        &#39;min_samples_leaf&#39;: range(10, 60, 10),</span></span>
<span class="line"><span style="color:#e1e4e8;">                       </span></span>
<span class="line"><span style="color:#e1e4e8;">#                        &#39;max_features&#39;: range(3, 11, 2)</span></span>
<span class="line"><span style="color:#e1e4e8;">#                    },</span></span>
<span class="line"><span style="color:#e1e4e8;">#                    scoring=&#39;roc_auc&#39;, cv=4)</span></span>
<span class="line"><span style="color:#e1e4e8;"># grid.fit(X, y)</span></span>
<span class="line"><span style="color:#e1e4e8;"># print(grid.best_params_, grid.best_score_)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># 模型</span></span>
<span class="line"><span style="color:#e1e4e8;">rf = RandomForestClassifier(oob_score=True, </span></span>
<span class="line"><span style="color:#e1e4e8;">                            n_estimators=60, </span></span>
<span class="line"><span style="color:#e1e4e8;">                            max_depth=13, </span></span>
<span class="line"><span style="color:#e1e4e8;">                            min_samples_split=120, </span></span>
<span class="line"><span style="color:#e1e4e8;">                            min_samples_leaf=20,</span></span>
<span class="line"><span style="color:#e1e4e8;">                            max_features=7,</span></span>
<span class="line"><span style="color:#e1e4e8;">                            random_state=10)</span></span>
<span class="line"><span style="color:#e1e4e8;">rf.fit(X, y)</span></span>
<span class="line"><span style="color:#e1e4e8;">print(rf.oob_score_)</span></span>
<span class="line"><span style="color:#e1e4e8;">predict = rf.predict_proba(X)[:, 1]</span></span>
<span class="line"><span style="color:#e1e4e8;">print(metrics.roc_auc_score(y, predict))</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">import pandas as pd</span></span>
<span class="line"><span style="color:#24292e;">import numpy as np</span></span>
<span class="line"><span style="color:#24292e;">import matplotlib.pyplot as plt</span></span>
<span class="line"><span style="color:#24292e;">from sklearn.ensemble import RandomForestClassifier</span></span>
<span class="line"><span style="color:#24292e;">from sklearn.model_selection import GridSearchCV</span></span>
<span class="line"><span style="color:#24292e;">from sklearn.model_selection import cross_val_predict</span></span>
<span class="line"><span style="color:#24292e;">from sklearn import metrics</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># 数据</span></span>
<span class="line"><span style="color:#24292e;">train = pd.read_csv(&#39;train_modified.csv&#39;)</span></span>
<span class="line"><span style="color:#24292e;">target=&#39;Disbursed&#39; # Disbursed的值就是二元分类的输出</span></span>
<span class="line"><span style="color:#24292e;">IDcol = &#39;ID&#39;</span></span>
<span class="line"><span style="color:#24292e;">train[&#39;Disbursed&#39;].value_counts() </span></span>
<span class="line"><span style="color:#24292e;">x_columns = [x for x in train.columns if x not in [target, IDcol]]</span></span>
<span class="line"><span style="color:#24292e;">X = train[x_columns]</span></span>
<span class="line"><span style="color:#24292e;">y = train[&#39;Disbursed&#39;]</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># 网格搜索</span></span>
<span class="line"><span style="color:#24292e;"># grid = GridSearchCV(estimator=RandomForestClassifier(n_estimators=60, </span></span>
<span class="line"><span style="color:#24292e;">#                                                      max_depth = 13,</span></span>
<span class="line"><span style="color:#24292e;">#                                                      min_samples_split=120, </span></span>
<span class="line"><span style="color:#24292e;">#                                                      min_samples_leaf=20,</span></span>
<span class="line"><span style="color:#24292e;">#                                                      random_state=10),</span></span>
<span class="line"><span style="color:#24292e;">#                    param_grid={</span></span>
<span class="line"><span style="color:#24292e;"># #                        &#39;n_estimators&#39;: range(10, 71, 10),</span></span>
<span class="line"><span style="color:#24292e;">                       </span></span>
<span class="line"><span style="color:#24292e;"># #                        &#39;max_depth&#39;: range(3, 14, 2),  </span></span>
<span class="line"><span style="color:#24292e;"># #                        &#39;min_samples_split&#39;: range(50, 201, 20),</span></span>
<span class="line"><span style="color:#24292e;">                       </span></span>
<span class="line"><span style="color:#24292e;"># #                        &#39;min_samples_split&#39;: range(80, 150, 20),</span></span>
<span class="line"><span style="color:#24292e;"># #                        &#39;min_samples_leaf&#39;: range(10, 60, 10),</span></span>
<span class="line"><span style="color:#24292e;">                       </span></span>
<span class="line"><span style="color:#24292e;">#                        &#39;max_features&#39;: range(3, 11, 2)</span></span>
<span class="line"><span style="color:#24292e;">#                    },</span></span>
<span class="line"><span style="color:#24292e;">#                    scoring=&#39;roc_auc&#39;, cv=4)</span></span>
<span class="line"><span style="color:#24292e;"># grid.fit(X, y)</span></span>
<span class="line"><span style="color:#24292e;"># print(grid.best_params_, grid.best_score_)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># 模型</span></span>
<span class="line"><span style="color:#24292e;">rf = RandomForestClassifier(oob_score=True, </span></span>
<span class="line"><span style="color:#24292e;">                            n_estimators=60, </span></span>
<span class="line"><span style="color:#24292e;">                            max_depth=13, </span></span>
<span class="line"><span style="color:#24292e;">                            min_samples_split=120, </span></span>
<span class="line"><span style="color:#24292e;">                            min_samples_leaf=20,</span></span>
<span class="line"><span style="color:#24292e;">                            max_features=7,</span></span>
<span class="line"><span style="color:#24292e;">                            random_state=10)</span></span>
<span class="line"><span style="color:#24292e;">rf.fit(X, y)</span></span>
<span class="line"><span style="color:#24292e;">print(rf.oob_score_)</span></span>
<span class="line"><span style="color:#24292e;">predict = rf.predict_proba(X)[:, 1]</span></span>
<span class="line"><span style="color:#24292e;">print(metrics.roc_auc_score(y, predict))</span></span></code></pre></div>`,33);function Q(u,f,x,b,H,L){return n(),e("div",null,[r,c,m,s("p",null,[a("每个样本被采样概率为1/m，不被采样概率为1-1/m。如果m次采样都没有被采集的概率为"),s("mjx-container",d,[(n(),e("svg",y,_)),h]),a("，当m趋于无穷大，约等于0.368。也就是说，bagging每轮随机采样，训练集中大学有36.8%的数据没有被采集到。这些数据被称为袋外数据（Out of Bag，简称OOB），因此，可以用来检测模型的泛化能力。")]),g])}const k=p(i,[["render",Q]]);export{V as __pageData,k as default};
