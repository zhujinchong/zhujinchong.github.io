import{_ as t,o as e,c as a,Q as l}from"./chunks/framework.2516552c.js";const i="/assets/640-1690696384724.77e0702c.png",n="/assets/640-1690696541034.918b678c.png",_=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"articles/Algorithm/13LLM/25Vicuna.md","filePath":"articles/Algorithm/13LLM/25Vicuna.md","lastUpdated":null}'),d={name:"articles/Algorithm/13LLM/25Vicuna.md"},s=l('<p>时间：20230512</p><h2 id="vicuna简介" tabindex="-1">Vicuna简介 <a class="header-anchor" href="#vicuna简介" aria-label="Permalink to &quot;Vicuna简介&quot;">​</a></h2><p>继斯坦福羊驼（Stanford Alpaca）之后，UC伯克利、CMU、斯坦福等机构的学者，联手发布了最新开源大模型骆马（Vicuna），包含7B和13B参数。其中，13B参数模型，训练成本仅需300美元，达到了ChatGPT的90%以上的能力，初步评估总结如图所示：</p><p><img src="'+i+'" alt="图片"></p><h3 id="vicuna工作流程" tabindex="-1">Vicuna工作流程 <a class="header-anchor" href="#vicuna工作流程" aria-label="Permalink to &quot;Vicuna工作流程&quot;">​</a></h3><p>Vicuna具体的工作流程如下图所示，首先，研究人员从 ShareGPT.com（一个供用户分享 ChatGPT 对话内容的网站）收集了约 7 万个对话，并增强了 Alpaca 提供的训练脚本，以更好地处理多轮对话和长序列。训练是在一天内通过 <strong>8 卡 A100 GPU 配合 PyTOrch FSDP</strong> 进行的full fine-tune。为了提供演示服务，Vicuna研究人员建立了一个轻量级的分布式服务系统，创建了八个问题类别（如：角色扮演、编码/数学任务等）的 80 个不同问题，利用 GPT-4 来判断模型输出，借此对模型质量做初步评估。为了比较两个不同的模型，Vicuna研究人员将每个模型的输出组合成每个问题的单个提示。然后将提示发送到 GPT-4，GPT-4 评估哪个模型提供更好的响应。</p><p><img src="'+n+'" alt="图片"></p><p>LLaMA、Alpaca、Vicuna和ChatGPT的详细对比如下所示：</p><table><thead><tr><th style="text-align:left;">模型名</th><th style="text-align:left;">LLaMA</th><th style="text-align:left;">Alpaca</th><th style="text-align:left;">Vicuna</th><th style="text-align:left;">Bard/ChatGPT</th></tr></thead><tbody><tr><td style="text-align:left;">数据集</td><td style="text-align:left;">公开可用的数据集 (1T token)</td><td style="text-align:left;">Self-instruct from davinci-003 API (52K samples)</td><td style="text-align:left;">用户共享对话 (70K samples)</td><td style="text-align:left;">N/A</td></tr><tr><td style="text-align:left;">训练代码</td><td style="text-align:left;">N/A</td><td style="text-align:left;">Available</td><td style="text-align:left;">Available</td><td style="text-align:left;">N/A</td></tr><tr><td style="text-align:left;">评估指标</td><td style="text-align:left;">Academic benchmark</td><td style="text-align:left;">Author evaluation</td><td style="text-align:left;">GPT-4 评估</td><td style="text-align:left;">Mixed</td></tr><tr><td style="text-align:left;">训练费用(7B)</td><td style="text-align:left;">82K GPU-hours</td><td style="text-align:left;"><code>$500 (data) + $100 (training)</code></td><td style="text-align:left;">$140 (training)</td><td style="text-align:left;">N/A</td></tr><tr><td style="text-align:left;">训练费用 (13B)</td><td style="text-align:left;">135K GPU-hours</td><td style="text-align:left;">N/A</td><td style="text-align:left;">$300 (training)</td><td style="text-align:left;">N/A</td></tr></tbody></table><h3 id="vicuna-局限性" tabindex="-1">Vicuna 局限性 <a class="header-anchor" href="#vicuna-局限性" aria-label="Permalink to &quot;Vicuna 局限性&quot;">​</a></h3><p>研究人员指出，与其他大语言模型类似，Vicuna也存在着一定的局限性。</p><p>比如，Vicuna在涉及编程、推理、数学以及事实准确性的任务上表现不佳。</p><p>此外，它也没有经过充分优化以保证安全性或减轻潜在的毒性或偏见。</p><p>为解决安全方面的问题，研究人员在实例中采用了OpenAI的审查API来过滤掉不适当的用户输入。</p><p>原文：</p><p><a href="https://mp.weixin.qq.com/s/qQ6cB3u7_lQI_AqqC-i6ng" target="_blank" rel="noreferrer">https://mp.weixin.qq.com/s/qQ6cB3u7_lQI_AqqC-i6ng</a></p>',16),r=[s];function c(o,p,h,f,g,u){return e(),a("div",null,r)}const y=t(d,[["render",c]]);export{_ as __pageData,y as default};
