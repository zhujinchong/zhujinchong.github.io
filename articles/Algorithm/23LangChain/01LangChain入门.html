<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>参考 | Make each day count, Make learning a habit.</title>
    <meta name="description" content="一只程序猿">
    <link rel="preload stylesheet" href="/assets/style.f8b36329.css" as="style">
    
    <script type="module" src="/assets/app.dc5e2f50.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.2ed14f66.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/framework.2516552c.js">
    <link rel="modulepreload" href="/assets/chunks/theme.2359dc4a.js">
    <link rel="modulepreload" href="/assets/articles_Algorithm_23LangChain_01LangChain入门.md.f19d9991.lean.js">
    <link rel="icon" href="/img/home.svg">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5a346dfe><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5a346dfe data-v-ae24b3ad><div class="VPNavBar has-sidebar" data-v-ae24b3ad data-v-a0fd61f4><div class="container" data-v-a0fd61f4><div class="title" data-v-a0fd61f4><div class="VPNavBarTitle has-sidebar" data-v-a0fd61f4 data-v-86d1bed8><a class="title" href="/" data-v-86d1bed8><!--[--><!--]--><!----><!--[-->Home<!--]--><!--[--><!--]--></a></div></div><div class="content" data-v-a0fd61f4><div class="curtain" data-v-a0fd61f4></div><div class="content-body" data-v-a0fd61f4><!--[--><!--]--><div class="VPNavBarSearch search" data-v-a0fd61f4><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-a0fd61f4 data-v-7f418b0f><span id="main-nav-aria-label" class="visually-hidden" data-v-7f418b0f>Main Navigation</span><!--[--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>Algorithm</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Algorithm/01python语法&amp;工具/" data-v-43f1e123><!--[-->01python语法&amp;工具<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Algorithm/10白板推导系列/" data-v-43f1e123><!--[-->10白板推导系列<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Algorithm/11强化学习/" data-v-43f1e123><!--[-->11强化学习<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Algorithm/12LLM/" data-v-43f1e123><!--[-->12LLM<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Algorithm/12机器学习笔记/" data-v-43f1e123><!--[-->12机器学习笔记<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Algorithm/21模型部署/" data-v-43f1e123><!--[-->21模型部署<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Algorithm/22模型训练和微调/" data-v-43f1e123><!--[-->22模型训练和微调<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Algorithm/23LangChain/" data-v-43f1e123><!--[-->23LangChain<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/articles/Blog/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>Blog</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>Java</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/01Java语法/" data-v-43f1e123><!--[-->01Java语法<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/02HTML+CSS+JS+XML/" data-v-43f1e123><!--[-->02HTML+CSS+JS+XML<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/03JavaWeb基础tomcat servlet jsp/" data-v-43f1e123><!--[-->03JavaWeb基础tomcat servlet jsp<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/05Maven/" data-v-43f1e123><!--[-->05Maven<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/20mysql/" data-v-43f1e123><!--[-->20mysql<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/22JanusGraph/" data-v-43f1e123><!--[-->22JanusGraph<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/30设计模式/" data-v-43f1e123><!--[-->30设计模式<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/31Java并发编程/" data-v-43f1e123><!--[-->31Java并发编程<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/51SpringBoot/" data-v-43f1e123><!--[-->51SpringBoot<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/52SpringCloud/" data-v-43f1e123><!--[-->52SpringCloud<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/53Arthus/" data-v-43f1e123><!--[-->53Arthus<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/60kafka/" data-v-43f1e123><!--[-->60kafka<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/61ElasticSearch/" data-v-43f1e123><!--[-->61ElasticSearch<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/65redis/" data-v-43f1e123><!--[-->65redis<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/65vue/" data-v-43f1e123><!--[-->65vue<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Java/66jenkins/" data-v-43f1e123><!--[-->66jenkins<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>Ops</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Ops/Docker/" data-v-43f1e123><!--[-->Docker<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Ops/Git/" data-v-43f1e123><!--[-->Git<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Ops/Linux/" data-v-43f1e123><!--[-->Linux<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Ops/Nginx/" data-v-43f1e123><!--[-->Nginx<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/articles/Ops/k8s/" data-v-43f1e123><!--[-->k8s<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/articles/VitePress/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>VitePress</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/articles/windows/" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>windows</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-a0fd61f4 data-v-e6aabb21><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="toggle dark mode" aria-checked="false" data-v-e6aabb21 data-v-ce54a7d1 data-v-b1685198><span class="check" data-v-b1685198><span class="icon" data-v-b1685198><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-ce54a7d1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-ce54a7d1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><!----><div class="VPFlyout VPNavBarExtra extra" data-v-a0fd61f4 data-v-40855f84 data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-9c007e85><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-9c007e85><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><!----><!--[--><!--[--><!----><div class="group" data-v-40855f84><div class="item appearance" data-v-40855f84><p class="label" data-v-40855f84>Appearance</p><div class="appearance-action" data-v-40855f84><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="toggle dark mode" aria-checked="false" data-v-40855f84 data-v-ce54a7d1 data-v-b1685198><span class="check" data-v-b1685198><span class="icon" data-v-b1685198><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-ce54a7d1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-ce54a7d1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-a0fd61f4 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><!----></header><div class="VPLocalNav reached-top" data-v-5a346dfe data-v-79c8c1df><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-79c8c1df><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-79c8c1df><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-79c8c1df>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-79c8c1df data-v-1c15a60a><button data-v-1c15a60a>Return to top</button><!----></div></div><aside class="VPSidebar" data-v-5a346dfe data-v-b00e2fdd><div class="curtain" data-v-b00e2fdd></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-b00e2fdd><span class="visually-hidden" id="sidebar-aria-label" data-v-b00e2fdd> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-b00e2fdd><section class="VPSidebarItem level-0 has-active" data-v-b00e2fdd data-v-e31bd47b><div class="item" role="button" tabindex="0" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><h2 class="text" data-v-e31bd47b>23LangChain</h2><!----></div><div class="items" data-v-e31bd47b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/articles/Algorithm/23LangChain/00%E5%9F%BA%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E5%BA%94%E7%94%A8%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>00基于大语言模型知识问答应用落地实践</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/articles/Algorithm/23LangChain/01LangChain%E5%85%A5%E9%97%A8.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>01LangChain入门</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/articles/Algorithm/23LangChain/02%E5%B7%A5%E5%85%B7%E6%80%BB%E7%BB%93.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>02工具总结</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/articles/Algorithm/23LangChain/03LangChain%E6%A3%80%E7%B4%A2.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>03LangChain检索</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5a346dfe data-v-669faec9><div class="VPDoc has-sidebar has-aside" data-v-669faec9 data-v-6b87e69f><!--[--><!--]--><div class="container" data-v-6b87e69f><div class="aside" data-v-6b87e69f><div class="aside-curtain" data-v-6b87e69f></div><div class="aside-container" data-v-6b87e69f><div class="aside-content" data-v-6b87e69f><div class="VPDocAside" data-v-6b87e69f data-v-3f215769><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" role="navigation" data-v-3f215769 data-v-d330b1bb><div class="content" data-v-d330b1bb><div class="outline-marker" data-v-d330b1bb></div><div class="outline-title" role="heading" aria-level="2" data-v-d330b1bb>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-d330b1bb><span class="visually-hidden" id="doc-outline-aria-label" data-v-d330b1bb> Table of Contents for current page </span><ul class="root" data-v-d330b1bb data-v-d0ee3533><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-6b87e69f><div class="content-container" data-v-6b87e69f><!--[--><!--]--><!----><main class="main" data-v-6b87e69f><div style="position:relative;" class="vp-doc _articles_Algorithm_23LangChain_01LangChain%E5%85%A5%E9%97%A8" data-v-6b87e69f><div><h1 id="参考" tabindex="-1">参考 <a class="header-anchor" href="#参考" aria-label="Permalink to &quot;参考&quot;">​</a></h1><p>入门代码示例，这篇文章非常好：</p><p>[LangChain快速入门级示例(chatglm+text2vec建立本地知识库) - 知乎 (zhihu.com)]</p><p><a href="https://zhuanlan.zhihu.com/p/630200571" target="_blank" rel="noreferrer">https://zhuanlan.zhihu.com/p/630200571</a></p><p>一些列教程：概念+代码理解</p><p>[从零开始学LangChain（1）：介绍和入门 - 知乎 (zhihu.com)]</p><p><a href="https://zhuanlan.zhihu.com/p/627600539" target="_blank" rel="noreferrer">https://zhuanlan.zhihu.com/p/627600539</a></p><p>LangChain和知识图谱、数据库的结合：</p><p><a href="https://blog.csdn.net/v_JULY_v/article/details/131552592" target="_blank" rel="noreferrer">https://blog.csdn.net/v_JULY_v/article/details/131552592</a></p><h1 id="langchain是什么" tabindex="-1">LangChain是什么？ <a class="header-anchor" href="#langchain是什么" aria-label="Permalink to &quot;LangChain是什么？&quot;">​</a></h1><p>LangChain创建于2022年10月，是围绕LLMs（大语言模型）建立的一个框架，LLMs使用机器学习算法和海量数据来分析和理解自然语言，GPT3.5、GPT4是LLMs最先进的代表，国内百度的文心一言、阿里的通义千问也属于LLMs。LangChain自身并不开发LLMs，它的核心理念是为各种LLMs实现通用的接口，把LLMs相关的组件“链接”在一起，简化LLMs应用的开发难度，方便开发者快速地开发复杂的LLMs应用。LangChain目前有两个语言的实现：python和nodejs。</p><p>接下来我们从两个方面全面的了解LangChain，一是LangChain组件的基础概念，二是LangChain常见的使用场景。</p><p>一个LangChain应用是通过很多个组件实现的，LangChain主要支持6种组件：</p><ul><li>Models：模型，各种类型的模型和模型集成，比如GPT-4</li><li>Prompts：提示，包括提示管理、提示优化和提示序列化</li><li>Memory：记忆，用来保存和模型交互时的上下文状态</li><li>Indexes：索引，用来结构化文档，以便和模型交互</li><li>Chains：链，一系列对各种组件的调用</li><li>Agents：代理，决定模型采取哪些行动，执行并且观察流程，直到完成为止</li></ul><p>使用场景：</p><ul><li>个人助手</li><li>基于文档的问答系统</li><li>聊天机器人</li><li>Tabular数据查询</li><li>API交互</li><li>信息提取</li><li>文档总结</li></ul><p>安装</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">pip install langchain</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">pip install langchain</span></span></code></pre></div><h1 id="组件" tabindex="-1">组件 <a class="header-anchor" href="#组件" aria-label="Permalink to &quot;组件&quot;">​</a></h1><h2 id="_1-模型models" tabindex="-1">1 模型Models <a class="header-anchor" href="#_1-模型models" aria-label="Permalink to &quot;1 模型Models&quot;">​</a></h2><p>LangChain支持的模型可以分为三类，它们的使用场景不同，输入和输出不同，开发者需要根据项目需要选择相应的类型。</p><h3 id="llms" tabindex="-1">LLMs <a class="header-anchor" href="#llms" aria-label="Permalink to &quot;LLMs&quot;">​</a></h3><p>langchain支持许多LLMs，如OpenAI</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain.llms import OpenAI</span></span>
<span class="line"><span style="color:#e1e4e8;">llm = OpenAI(model_name=&quot;text-davinci-003&quot;, n=2, temperature=0.3)</span></span>
<span class="line"><span style="color:#e1e4e8;">llm(&quot;你好&quot;)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain.llms import OpenAI</span></span>
<span class="line"><span style="color:#24292e;">llm = OpenAI(model_name=&quot;text-davinci-003&quot;, n=2, temperature=0.3)</span></span>
<span class="line"><span style="color:#24292e;">llm(&quot;你好&quot;)</span></span></code></pre></div><p>但是，我们一般用本地LLM，如ChatGLM2-6B</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from transformers import AutoTokenizer, AutoModel</span></span>
<span class="line"><span style="color:#e1e4e8;">class chatGLM():</span></span>
<span class="line"><span style="color:#e1e4e8;">    def __init__(self, model_name) -&gt; None:</span></span>
<span class="line"><span style="color:#e1e4e8;">        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)</span></span>
<span class="line"><span style="color:#e1e4e8;">        self.model = AutoModel.from_pretrained(model_name, trust_remote_code=True).half().cuda().eval()</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">    def __call__(self, prompt) -&gt; Any:</span></span>
<span class="line"><span style="color:#e1e4e8;">        response, _ = self.model.chat(self.tokenizer , prompt) # 这里演示未使用流式接口. stream_chat()</span></span>
<span class="line"><span style="color:#e1e4e8;">        return response</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">llm =  chatGLM(model_name=&quot;THUDM/chatglm-6b&quot;)</span></span>
<span class="line"><span style="color:#e1e4e8;">response = llm(&quot;你好&quot;)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from transformers import AutoTokenizer, AutoModel</span></span>
<span class="line"><span style="color:#24292e;">class chatGLM():</span></span>
<span class="line"><span style="color:#24292e;">    def __init__(self, model_name) -&gt; None:</span></span>
<span class="line"><span style="color:#24292e;">        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)</span></span>
<span class="line"><span style="color:#24292e;">        self.model = AutoModel.from_pretrained(model_name, trust_remote_code=True).half().cuda().eval()</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">    def __call__(self, prompt) -&gt; Any:</span></span>
<span class="line"><span style="color:#24292e;">        response, _ = self.model.chat(self.tokenizer , prompt) # 这里演示未使用流式接口. stream_chat()</span></span>
<span class="line"><span style="color:#24292e;">        return response</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">llm =  chatGLM(model_name=&quot;THUDM/chatglm-6b&quot;)</span></span>
<span class="line"><span style="color:#24292e;">response = llm(&quot;你好&quot;)</span></span></code></pre></div><h3 id="聊天模型" tabindex="-1">聊天模型 <a class="header-anchor" href="#聊天模型" aria-label="Permalink to &quot;聊天模型&quot;">​</a></h3><p>聊天模型基于LLMs，不同的是LLMs的输入输出是字符串，而聊天模型的输入输出是聊天消息。</p><p>聊天消息包含下面几种类型，使用时需要按照约定传入合适的值：</p><ul><li><strong>AIMessage</strong>：用来保存LLM的响应，以便在下次请求时把这些信息传回给LLM。</li><li><strong>HumanMessage</strong>：发送给LLMs的提示信息，比如“请写一个快速排序方法”</li><li><strong>SystemMessage</strong>：设置LLM模型的行为方式和目标。你可以在这里给出具体的指示，比如“作为一个代码专家”，或者“返回json格式”。</li><li><strong>ChatMessage</strong>：可以接收任意形式的值，但是在大多数时间，我们应该使用上面的三种类型</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain.chat_models import ChatOpenAI</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.schema import AIMessage, HumanMessage, SystemMessage</span></span>
<span class="line"><span style="color:#e1e4e8;">messages = [</span></span>
<span class="line"><span style="color:#e1e4e8;">        SystemMessage(content=&quot;返回json object，不要说明和解释信息&quot;),</span></span>
<span class="line"><span style="color:#e1e4e8;">        HumanMessage(content=&quot;告诉我model Y汽车的尺寸参数&quot;)</span></span>
<span class="line"><span style="color:#e1e4e8;">]</span></span>
<span class="line"><span style="color:#e1e4e8;">chat = ChatOpenAI(temperature=0)</span></span>
<span class="line"><span style="color:#e1e4e8;">chat(messages)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain.chat_models import ChatOpenAI</span></span>
<span class="line"><span style="color:#24292e;">from langchain.schema import AIMessage, HumanMessage, SystemMessage</span></span>
<span class="line"><span style="color:#24292e;">messages = [</span></span>
<span class="line"><span style="color:#24292e;">        SystemMessage(content=&quot;返回json object，不要说明和解释信息&quot;),</span></span>
<span class="line"><span style="color:#24292e;">        HumanMessage(content=&quot;告诉我model Y汽车的尺寸参数&quot;)</span></span>
<span class="line"><span style="color:#24292e;">]</span></span>
<span class="line"><span style="color:#24292e;">chat = ChatOpenAI(temperature=0)</span></span>
<span class="line"><span style="color:#24292e;">chat(messages)</span></span></code></pre></div><h3 id="文本嵌入模型-text-embedding-model" tabindex="-1">文本嵌入模型（Text Embedding Model） <a class="header-anchor" href="#文本嵌入模型-text-embedding-model" aria-label="Permalink to &quot;文本嵌入模型（Text Embedding Model）&quot;">​</a></h3><p>文本嵌入模型可以为文本创建向量映射，这样就能在向量空间里去考虑文本，执行诸如语义搜索之类的操作，比如说寻找相似的文本片段。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain.embeddings import OpenAIEmbeddings</span></span>
<span class="line"><span style="color:#e1e4e8;">embeddings = OpenAIEmbeddings()</span></span>
<span class="line"><span style="color:#e1e4e8;">query_result = embeddings.embed_query(&quot;你好&quot;)</span></span>
<span class="line"><span style="color:#e1e4e8;">doc_result = embeddings.embed_documents([&quot;你好&quot;])</span></span>
<span class="line"><span style="color:#e1e4e8;"># [-0.009422866627573967, 0.004315766040235758, 0.00238...]</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain.embeddings import OpenAIEmbeddings</span></span>
<span class="line"><span style="color:#24292e;">embeddings = OpenAIEmbeddings()</span></span>
<span class="line"><span style="color:#24292e;">query_result = embeddings.embed_query(&quot;你好&quot;)</span></span>
<span class="line"><span style="color:#24292e;">doc_result = embeddings.embed_documents([&quot;你好&quot;])</span></span>
<span class="line"><span style="color:#24292e;"># [-0.009422866627573967, 0.004315766040235758, 0.00238...]</span></span></code></pre></div><p>在这段代码中我们使用了<code>embed_query</code>和<code>embed_documents</code>两个方法，它们最大的不同是embed_query接收一个字符串作为输入，而embed_documents可以接收一组字符串，一些模型自身划分了这两个方法，LangChain也保留了下来。</p><h2 id="_2-提示prompts" tabindex="-1">2 提示Prompts <a class="header-anchor" href="#_2-提示prompts" aria-label="Permalink to &quot;2 提示Prompts&quot;">​</a></h2><p>提示模板：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain import PromptTemplate</span></span>
<span class="line"><span style="color:#e1e4e8;">template = &quot;我的邻居姓{lastname}，他生了个儿子，给他儿子起个名字&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;">prompt = PromptTemplate(input_variables=[&quot;lastname&quot;], template=template)</span></span>
<span class="line"><span style="color:#e1e4e8;">prompt_text = prompt.format(lastname=&quot;王&quot;)</span></span>
<span class="line"><span style="color:#e1e4e8;">print(prompt_text)</span></span>
<span class="line"><span style="color:#e1e4e8;"># # 我的邻居姓王，他生了个儿子，给他儿子起个名字</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain import PromptTemplate</span></span>
<span class="line"><span style="color:#24292e;">template = &quot;我的邻居姓{lastname}，他生了个儿子，给他儿子起个名字&quot;</span></span>
<span class="line"><span style="color:#24292e;">prompt = PromptTemplate(input_variables=[&quot;lastname&quot;], template=template)</span></span>
<span class="line"><span style="color:#24292e;">prompt_text = prompt.format(lastname=&quot;王&quot;)</span></span>
<span class="line"><span style="color:#24292e;">print(prompt_text)</span></span>
<span class="line"><span style="color:#24292e;"># # 我的邻居姓王，他生了个儿子，给他儿子起个名字</span></span></code></pre></div><p>Few-Shot prompt：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain import PromptTemplate, FewShotPromptTemplate</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">example_template = &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;">单词: {word}</span></span>
<span class="line"><span style="color:#e1e4e8;">反义词: {antonym}\\n</span></span>
<span class="line"><span style="color:#e1e4e8;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">example_prompt = PromptTemplate(input_variables=[&quot;word&quot;, &quot;antonym&quot;], template=example_template)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">examples = [</span></span>
<span class="line"><span style="color:#e1e4e8;">    {&quot;word&quot;: &quot;开心&quot;, &quot;antonym&quot;: &quot;难过&quot;},</span></span>
<span class="line"><span style="color:#e1e4e8;">    {&quot;word&quot;: &quot;高&quot;, &quot;antonym&quot;: &quot;矮&quot;},</span></span>
<span class="line"><span style="color:#e1e4e8;">]</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">few_shot_prompt = FewShotPromptTemplate(</span></span>
<span class="line"><span style="color:#e1e4e8;">    example_prompt=example_prompt,</span></span>
<span class="line"><span style="color:#e1e4e8;">    examples=examples,</span></span>
<span class="line"><span style="color:#e1e4e8;">    prefix=&quot;给出每个单词的反义词&quot;,</span></span>
<span class="line"><span style="color:#e1e4e8;">    suffix=&quot;单词: {input}\\n反义词:&quot;,</span></span>
<span class="line"><span style="color:#e1e4e8;">    input_variables=[&quot;input&quot;],</span></span>
<span class="line"><span style="color:#e1e4e8;">    example_separator=&quot;\\n&quot;,</span></span>
<span class="line"><span style="color:#e1e4e8;">)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">prompt_text = few_shot_prompt.format(input=&quot;粗&quot;)</span></span>
<span class="line"><span style="color:#e1e4e8;">print(prompt_text)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># 给出每个单词的反义词</span></span>
<span class="line"><span style="color:#e1e4e8;"># 单词: 开心</span></span>
<span class="line"><span style="color:#e1e4e8;"># 反义词: 难过</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># 单词: 高</span></span>
<span class="line"><span style="color:#e1e4e8;"># 反义词: 矮</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># 单词: 粗</span></span>
<span class="line"><span style="color:#e1e4e8;"># 反义词:</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain import PromptTemplate, FewShotPromptTemplate</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">example_template = &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292e;">单词: {word}</span></span>
<span class="line"><span style="color:#24292e;">反义词: {antonym}\\n</span></span>
<span class="line"><span style="color:#24292e;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">example_prompt = PromptTemplate(input_variables=[&quot;word&quot;, &quot;antonym&quot;], template=example_template)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">examples = [</span></span>
<span class="line"><span style="color:#24292e;">    {&quot;word&quot;: &quot;开心&quot;, &quot;antonym&quot;: &quot;难过&quot;},</span></span>
<span class="line"><span style="color:#24292e;">    {&quot;word&quot;: &quot;高&quot;, &quot;antonym&quot;: &quot;矮&quot;},</span></span>
<span class="line"><span style="color:#24292e;">]</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">few_shot_prompt = FewShotPromptTemplate(</span></span>
<span class="line"><span style="color:#24292e;">    example_prompt=example_prompt,</span></span>
<span class="line"><span style="color:#24292e;">    examples=examples,</span></span>
<span class="line"><span style="color:#24292e;">    prefix=&quot;给出每个单词的反义词&quot;,</span></span>
<span class="line"><span style="color:#24292e;">    suffix=&quot;单词: {input}\\n反义词:&quot;,</span></span>
<span class="line"><span style="color:#24292e;">    input_variables=[&quot;input&quot;],</span></span>
<span class="line"><span style="color:#24292e;">    example_separator=&quot;\\n&quot;,</span></span>
<span class="line"><span style="color:#24292e;">)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">prompt_text = few_shot_prompt.format(input=&quot;粗&quot;)</span></span>
<span class="line"><span style="color:#24292e;">print(prompt_text)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># 给出每个单词的反义词</span></span>
<span class="line"><span style="color:#24292e;"># 单词: 开心</span></span>
<span class="line"><span style="color:#24292e;"># 反义词: 难过</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># 单词: 高</span></span>
<span class="line"><span style="color:#24292e;"># 反义词: 矮</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># 单词: 粗</span></span>
<span class="line"><span style="color:#24292e;"># 反义词:</span></span></code></pre></div><h2 id="_3-链chains" tabindex="-1">3 链Chains <a class="header-anchor" href="#_3-链chains" aria-label="Permalink to &quot;3 链Chains&quot;">​</a></h2><p>Chains就是将Models和其他组件组合起来。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain import PromptTemplate</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.llms import OpenAI</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.chains import LLMChain</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">template = &quot;我的邻居姓{lastname}，他生了个儿子，给他儿子起个名字&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">prompt = PromptTemplate(</span></span>
<span class="line"><span style="color:#e1e4e8;">    input_variables=[&quot;lastname&quot;],</span></span>
<span class="line"><span style="color:#e1e4e8;">    template=template,</span></span>
<span class="line"><span style="color:#e1e4e8;">)</span></span>
<span class="line"><span style="color:#e1e4e8;">llm = OpenAI(temperature=0.9)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">chain = LLMChain(llm=llm, prompt=prompt)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># 执行链</span></span>
<span class="line"><span style="color:#e1e4e8;">print(chain.run(&quot;王&quot;))</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># # 可以叫王子，也可以叫小王或者小王子等等。</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain import PromptTemplate</span></span>
<span class="line"><span style="color:#24292e;">from langchain.llms import OpenAI</span></span>
<span class="line"><span style="color:#24292e;">from langchain.chains import LLMChain</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">template = &quot;我的邻居姓{lastname}，他生了个儿子，给他儿子起个名字&quot;</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">prompt = PromptTemplate(</span></span>
<span class="line"><span style="color:#24292e;">    input_variables=[&quot;lastname&quot;],</span></span>
<span class="line"><span style="color:#24292e;">    template=template,</span></span>
<span class="line"><span style="color:#24292e;">)</span></span>
<span class="line"><span style="color:#24292e;">llm = OpenAI(temperature=0.9)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">chain = LLMChain(llm=llm, prompt=prompt)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># 执行链</span></span>
<span class="line"><span style="color:#24292e;">print(chain.run(&quot;王&quot;))</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># # 可以叫王子，也可以叫小王或者小王子等等。</span></span></code></pre></div><p>如果我们想把第一个模型的输出，作为第二个模型的输入，可以使用LangChain的<code>SimpleSequentialChain</code></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain import PromptTemplate</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.llms import OpenAI</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.chains import LLMChain, SimpleSequentialChain</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">template = &quot;我的邻居姓{lastname}，他生了个儿子，给他儿子起个名字&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">prompt = PromptTemplate(</span></span>
<span class="line"><span style="color:#e1e4e8;">    input_variables=[&quot;lastname&quot;],</span></span>
<span class="line"><span style="color:#e1e4e8;">    template=template,</span></span>
<span class="line"><span style="color:#e1e4e8;">)</span></span>
<span class="line"><span style="color:#e1e4e8;">llm = OpenAI(temperature=0.9)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">chain = LLMChain(llm = llm, </span></span>
<span class="line"><span style="color:#e1e4e8;">                  prompt = prompt)</span></span>
<span class="line"><span style="color:#e1e4e8;"># 创建第二条链</span></span>
<span class="line"><span style="color:#e1e4e8;">second_prompt = PromptTemplate(</span></span>
<span class="line"><span style="color:#e1e4e8;">    input_variables=[&quot;child_name&quot;],</span></span>
<span class="line"><span style="color:#e1e4e8;">    template=&quot;邻居的儿子名字叫{child_name}，给他起一个小名&quot;,</span></span>
<span class="line"><span style="color:#e1e4e8;">)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">chain_two = LLMChain(llm=llm, prompt=second_prompt)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># 链接两条链 </span></span>
<span class="line"><span style="color:#e1e4e8;">overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># 执行链，只需要传入第一个参数</span></span>
<span class="line"><span style="color:#e1e4e8;">catchphrase = overall_chain.run(&quot;王&quot;)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain import PromptTemplate</span></span>
<span class="line"><span style="color:#24292e;">from langchain.llms import OpenAI</span></span>
<span class="line"><span style="color:#24292e;">from langchain.chains import LLMChain, SimpleSequentialChain</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">template = &quot;我的邻居姓{lastname}，他生了个儿子，给他儿子起个名字&quot;</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">prompt = PromptTemplate(</span></span>
<span class="line"><span style="color:#24292e;">    input_variables=[&quot;lastname&quot;],</span></span>
<span class="line"><span style="color:#24292e;">    template=template,</span></span>
<span class="line"><span style="color:#24292e;">)</span></span>
<span class="line"><span style="color:#24292e;">llm = OpenAI(temperature=0.9)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">chain = LLMChain(llm = llm, </span></span>
<span class="line"><span style="color:#24292e;">                  prompt = prompt)</span></span>
<span class="line"><span style="color:#24292e;"># 创建第二条链</span></span>
<span class="line"><span style="color:#24292e;">second_prompt = PromptTemplate(</span></span>
<span class="line"><span style="color:#24292e;">    input_variables=[&quot;child_name&quot;],</span></span>
<span class="line"><span style="color:#24292e;">    template=&quot;邻居的儿子名字叫{child_name}，给他起一个小名&quot;,</span></span>
<span class="line"><span style="color:#24292e;">)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">chain_two = LLMChain(llm=llm, prompt=second_prompt)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># 链接两条链 </span></span>
<span class="line"><span style="color:#24292e;">overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># 执行链，只需要传入第一个参数</span></span>
<span class="line"><span style="color:#24292e;">catchphrase = overall_chain.run(&quot;王&quot;)</span></span></code></pre></div><p>Chatglm对象不符合LLMChain类llm对象要求，模仿一下</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">class DemoChain():</span></span>
<span class="line"><span style="color:#e1e4e8;">    def __init__(self, llm, prompt) -&gt; None:</span></span>
<span class="line"><span style="color:#e1e4e8;">        self.llm = llm</span></span>
<span class="line"><span style="color:#e1e4e8;">        self.prompt = prompt</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">    def run(self, query) -&gt; Any:</span></span>
<span class="line"><span style="color:#e1e4e8;">        prompt = self.prompt.format(concept=query)</span></span>
<span class="line"><span style="color:#e1e4e8;">        print(&quot;query=%s  -&gt;prompt=%s&quot;%(query, prompt))</span></span>
<span class="line"><span style="color:#e1e4e8;">        response = self.llm(prompt) </span></span>
<span class="line"><span style="color:#e1e4e8;">        return response</span></span>
<span class="line"><span style="color:#e1e4e8;">    </span></span>
<span class="line"><span style="color:#e1e4e8;">chain = DemoChain(llm=llm, prompt=promptTem)</span></span>
<span class="line"><span style="color:#e1e4e8;">print(chain.run(query=&quot;天道酬勤&quot;))</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">class DemoChain():</span></span>
<span class="line"><span style="color:#24292e;">    def __init__(self, llm, prompt) -&gt; None:</span></span>
<span class="line"><span style="color:#24292e;">        self.llm = llm</span></span>
<span class="line"><span style="color:#24292e;">        self.prompt = prompt</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">    def run(self, query) -&gt; Any:</span></span>
<span class="line"><span style="color:#24292e;">        prompt = self.prompt.format(concept=query)</span></span>
<span class="line"><span style="color:#24292e;">        print(&quot;query=%s  -&gt;prompt=%s&quot;%(query, prompt))</span></span>
<span class="line"><span style="color:#24292e;">        response = self.llm(prompt) </span></span>
<span class="line"><span style="color:#24292e;">        return response</span></span>
<span class="line"><span style="color:#24292e;">    </span></span>
<span class="line"><span style="color:#24292e;">chain = DemoChain(llm=llm, prompt=promptTem)</span></span>
<span class="line"><span style="color:#24292e;">print(chain.run(query=&quot;天道酬勤&quot;))</span></span></code></pre></div><h2 id="_4-代理agents" tabindex="-1">4 代理Agents <a class="header-anchor" href="#_4-代理agents" aria-label="Permalink to &quot;4 代理Agents&quot;">​</a></h2><p>尽管大语言模型非常强大，它们也有一些局限性，它们不能回答实时信息，它们没有上下文的概念，导致无法保存状态，它们处理数学逻辑问题仍然非常初级，我们只能借助于第三方的工具来完成这些需求，比如使用搜索引擎或者数据库，LangChain中代理的作用就是根据用户需求，来去访问这些工具。</p><p>我们先明确几个概念：</p><p>1、代理</p><ul><li>负责控制整段代码的逻辑和执行，代理暴露了一个接口，用来接收用户输入，并返回AgentAction或AgentFinish。</li><li>AgentAction决定使用哪个工具</li><li>AgentFinish意味着代理的工作完成了，返回给用户结果</li></ul><p>2、工具</p><ul><li>第三方服务的集成，比如谷歌、bing等等，后面有详细列表</li></ul><p>3、工具包</p><ul><li>一些集成好了代理包，比如<code>create_csv_agent</code> 可以使用模型解读csv文件</li></ul><p>4、代理执行器</p><ul><li>负责迭代运行代理的循环，直到满足停止的标准。</li></ul><p>明确了这些概念，我们看个使用代理的例子，假如我们在北京，想让大语言模型告诉我们明天穿什么衣服，由于大语言模型不知道明天的天气，我们借助于<code>serpapi</code> 来查询天气，并传递给模型，代码如下：（使用serpapi需要申请token和设置环境变量，略）</p><div class="language-python3 vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python3</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain.agents import load_tools</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.agents import initialize_agent</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.agents import AgentType</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.llms import OpenAI</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">llm = OpenAI(temperature=0)</span></span>
<span class="line"><span style="color:#e1e4e8;">tools = load_tools([&quot;serpapi&quot;], llm=llm)</span></span>
<span class="line"><span style="color:#e1e4e8;">agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">agent.run(&quot;明天在北京穿什么衣服合适?&quot;)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain.agents import load_tools</span></span>
<span class="line"><span style="color:#24292e;">from langchain.agents import initialize_agent</span></span>
<span class="line"><span style="color:#24292e;">from langchain.agents import AgentType</span></span>
<span class="line"><span style="color:#24292e;">from langchain.llms import OpenAI</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">llm = OpenAI(temperature=0)</span></span>
<span class="line"><span style="color:#24292e;">tools = load_tools([&quot;serpapi&quot;], llm=llm)</span></span>
<span class="line"><span style="color:#24292e;">agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">agent.run(&quot;明天在北京穿什么衣服合适?&quot;)</span></span></code></pre></div><h2 id="_5-记忆memory" tabindex="-1">5 记忆Memory <a class="header-anchor" href="#_5-记忆memory" aria-label="Permalink to &quot;5 记忆Memory&quot;">​</a></h2><p>大语言模型是无状态的，它并不保存上次交互的内容，chatGPT能够和人正常对话，因为它做了一层包装，把历史记录传回给了模型。</p><p>为了解决这个问题，LangChain提供了记忆组件。记忆有两种类型：短期和长期记忆。短期记忆一般指单一会话时传递数据，长期记忆则是处理多个会话时获取和更新信息。</p><p>短期记忆用<code>ChatMessageHistory</code> ：</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain.memory import ChatMessageHistory</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">history = ChatMessageHistory()</span></span>
<span class="line"><span style="color:#e1e4e8;">history.add_user_message(&quot;在吗？&quot;)</span></span>
<span class="line"><span style="color:#e1e4e8;">history.add_ai_message(&quot;有什么事?&quot;)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">print(history.messages)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain.memory import ChatMessageHistory</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">history = ChatMessageHistory()</span></span>
<span class="line"><span style="color:#24292e;">history.add_user_message(&quot;在吗？&quot;)</span></span>
<span class="line"><span style="color:#24292e;">history.add_ai_message(&quot;有什么事?&quot;)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">print(history.messages)</span></span></code></pre></div><p>长期记忆使用<code>messages_to_dict</code> 方法：</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain.memory import ChatMessageHistory</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.schema import messages_from_dict, messages_to_dict</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">history = ChatMessageHistory()</span></span>
<span class="line"><span style="color:#e1e4e8;">history.add_user_message(&quot;hi!&quot;)</span></span>
<span class="line"><span style="color:#e1e4e8;">history.add_ai_message(&quot;whats up?&quot;)</span></span>
<span class="line"><span style="color:#e1e4e8;">dicts = messages_to_dict(history.messages)</span></span>
<span class="line"><span style="color:#e1e4e8;">print(dicts)</span></span>
<span class="line"><span style="color:#e1e4e8;"># # [{&#39;type&#39;: &#39;human&#39;, &#39;data&#39;: {&#39;content&#39;: &#39;hi!&#39;, &#39;additional_kwargs&#39;: {}}},</span></span>
<span class="line"><span style="color:#e1e4e8;"># # {&#39;type&#39;: &#39;ai&#39;, &#39;data&#39;: {&#39;content&#39;: &#39;whats up?&#39;, &#39;additional_kwargs&#39;: {}}}]</span></span>
<span class="line"><span style="color:#e1e4e8;"># 读取历史消息</span></span>
<span class="line"><span style="color:#e1e4e8;">new_messages = messages_from_dict(dicts)</span></span>
<span class="line"><span style="color:#e1e4e8;">print(new_messages)</span></span>
<span class="line"><span style="color:#e1e4e8;"># # [HumanMessage(content=&#39;hi!&#39;, additional_kwargs={}),</span></span>
<span class="line"><span style="color:#e1e4e8;"># # AIMessage(content=&#39;whats up?&#39;, additional_kwargs={})]</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain.memory import ChatMessageHistory</span></span>
<span class="line"><span style="color:#24292e;">from langchain.schema import messages_from_dict, messages_to_dict</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">history = ChatMessageHistory()</span></span>
<span class="line"><span style="color:#24292e;">history.add_user_message(&quot;hi!&quot;)</span></span>
<span class="line"><span style="color:#24292e;">history.add_ai_message(&quot;whats up?&quot;)</span></span>
<span class="line"><span style="color:#24292e;">dicts = messages_to_dict(history.messages)</span></span>
<span class="line"><span style="color:#24292e;">print(dicts)</span></span>
<span class="line"><span style="color:#24292e;"># # [{&#39;type&#39;: &#39;human&#39;, &#39;data&#39;: {&#39;content&#39;: &#39;hi!&#39;, &#39;additional_kwargs&#39;: {}}},</span></span>
<span class="line"><span style="color:#24292e;"># # {&#39;type&#39;: &#39;ai&#39;, &#39;data&#39;: {&#39;content&#39;: &#39;whats up?&#39;, &#39;additional_kwargs&#39;: {}}}]</span></span>
<span class="line"><span style="color:#24292e;"># 读取历史消息</span></span>
<span class="line"><span style="color:#24292e;">new_messages = messages_from_dict(dicts)</span></span>
<span class="line"><span style="color:#24292e;">print(new_messages)</span></span>
<span class="line"><span style="color:#24292e;"># # [HumanMessage(content=&#39;hi!&#39;, additional_kwargs={}),</span></span>
<span class="line"><span style="color:#24292e;"># # AIMessage(content=&#39;whats up?&#39;, additional_kwargs={})]</span></span></code></pre></div><h2 id="_6-索引indexes" tabindex="-1">6 索引Indexes <a class="header-anchor" href="#_6-索引indexes" aria-label="Permalink to &quot;6 索引Indexes&quot;">​</a></h2><p>索引组件为LangChain提供了文档处理的能力，包括文档加载、检索等等，这里的文档是广义的文档，不仅仅是txt、epub、pdf等文本类的内容，还包括email、区块链、telegram、Notion甚至是视频内容。</p><p>索引组件主要有以下四种类型：</p><ul><li>文档加载器</li><li>文本分割器</li><li>VectorStores</li><li>检索器</li></ul><h3 id="文档加载器" tabindex="-1">文档加载器 <a class="header-anchor" href="#文档加载器" aria-label="Permalink to &quot;文档加载器&quot;">​</a></h3><p>文档加载器主要基于<code>Unstructured</code> 包，<code>Unstructured</code> 是一个python包，可以把各种类型的文件转换成文本。文档加载器使用起来很简单，只需要引入相应的loader工具：</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain.document_loaders import TextLoader</span></span>
<span class="line"><span style="color:#e1e4e8;">loader = TextLoader(&#39;../state_of_the_union.txt&#39;, encoding=&#39;utf8&#39;)</span></span>
<span class="line"><span style="color:#e1e4e8;">documents = loader.load()</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain.document_loaders import TextLoader</span></span>
<span class="line"><span style="color:#24292e;">loader = TextLoader(&#39;../state_of_the_union.txt&#39;, encoding=&#39;utf8&#39;)</span></span>
<span class="line"><span style="color:#24292e;">documents = loader.load()</span></span></code></pre></div><h3 id="文本分割器" tabindex="-1">文本分割器 <a class="header-anchor" href="#文本分割器" aria-label="Permalink to &quot;文本分割器&quot;">​</a></h3><p>由于模型对输入的字符长度有限制，我们在碰到很长的文本时，需要把文本分割成多个小的文本片段。</p><p>文本分割最简单的方式是按照字符长度进行分割，但是这会带来很多问题，比如说如果文本是一段代码，一个函数被分割到两段之后就成了没有意义的字符，所以整体的原则是把语义相关的文本片段放在一起。</p><p>LangChain中最基本的文本分割器是<code>CharacterTextSplitter</code> ，它按照指定的分隔符（默认“\n\n”）进行分割，并且考虑文本片段的最大长度。我们看个例子：</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain.text_splitter import CharacterTextSplitter</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># 初始字符串</span></span>
<span class="line"><span style="color:#e1e4e8;">state_of_the_union = &quot;...&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">text_splitter = CharacterTextSplitter(        </span></span>
<span class="line"><span style="color:#e1e4e8;">    separator = &quot;\\n\\n&quot;,</span></span>
<span class="line"><span style="color:#e1e4e8;">    chunk_size = 1000,</span></span>
<span class="line"><span style="color:#e1e4e8;">    chunk_overlap  = 200,</span></span>
<span class="line"><span style="color:#e1e4e8;">    length_function = len,</span></span>
<span class="line"><span style="color:#e1e4e8;">)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">texts = text_splitter.create_documents([state_of_the_union])</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain.text_splitter import CharacterTextSplitter</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># 初始字符串</span></span>
<span class="line"><span style="color:#24292e;">state_of_the_union = &quot;...&quot;</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">text_splitter = CharacterTextSplitter(        </span></span>
<span class="line"><span style="color:#24292e;">    separator = &quot;\\n\\n&quot;,</span></span>
<span class="line"><span style="color:#24292e;">    chunk_size = 1000,</span></span>
<span class="line"><span style="color:#24292e;">    chunk_overlap  = 200,</span></span>
<span class="line"><span style="color:#24292e;">    length_function = len,</span></span>
<span class="line"><span style="color:#24292e;">)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">texts = text_splitter.create_documents([state_of_the_union])</span></span></code></pre></div><h3 id="向量存储库" tabindex="-1">向量存储库 <a class="header-anchor" href="#向量存储库" aria-label="Permalink to &quot;向量存储库&quot;">​</a></h3><p>VectorStores是一种特殊类型的数据库，它的作用是存储由嵌入创建的向量，提供相似查询等功能。</p><p><code>DeepLake</code> 和<code>Chroma</code> 都属于VectorStores，VectorStores的作用就是保存和检索向量，它们之间的区别也很明显，<code>DeepLake</code> 使用云服务器保存数据，而<code>Chroma</code> 则是完全的本地服务。</p><p><code>Chroma</code> 开源、轻量、性能良好，使用起来也很简单，只需使用pip安装chromadb即可。</p><p>我们使用其中一个<code>Chroma</code> 组件作为例子。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain.embeddings.openai import OpenAIEmbeddings</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.text_splitter import CharacterTextSplitter</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.vectorstores import Chroma</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;"># pku.txt内容：&lt;https://www.pku.edu.cn/about.html&gt;</span></span>
<span class="line"><span style="color:#e1e4e8;">with open(&#39;./pku.txt&#39;) as f:</span></span>
<span class="line"><span style="color:#e1e4e8;">    state_of_the_union = f.read()</span></span>
<span class="line"><span style="color:#e1e4e8;">text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)</span></span>
<span class="line"><span style="color:#e1e4e8;">texts = text_splitter.split_text(state_of_the_union)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">embeddings = OpenAIEmbeddings()</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">docsearch = Chroma.from_texts(texts, embeddings)</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">query = &quot;1937年北京大学发生了什么？&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;">docs = docsearch.similarity_search(query)</span></span>
<span class="line"><span style="color:#e1e4e8;">print(docs)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain.embeddings.openai import OpenAIEmbeddings</span></span>
<span class="line"><span style="color:#24292e;">from langchain.text_splitter import CharacterTextSplitter</span></span>
<span class="line"><span style="color:#24292e;">from langchain.vectorstores import Chroma</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;"># pku.txt内容：&lt;https://www.pku.edu.cn/about.html&gt;</span></span>
<span class="line"><span style="color:#24292e;">with open(&#39;./pku.txt&#39;) as f:</span></span>
<span class="line"><span style="color:#24292e;">    state_of_the_union = f.read()</span></span>
<span class="line"><span style="color:#24292e;">text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)</span></span>
<span class="line"><span style="color:#24292e;">texts = text_splitter.split_text(state_of_the_union)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">embeddings = OpenAIEmbeddings()</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">docsearch = Chroma.from_texts(texts, embeddings)</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">query = &quot;1937年北京大学发生了什么？&quot;</span></span>
<span class="line"><span style="color:#24292e;">docs = docsearch.similarity_search(query)</span></span>
<span class="line"><span style="color:#24292e;">print(docs)</span></span></code></pre></div><h3 id="检索器" tabindex="-1">检索器 <a class="header-anchor" href="#检索器" aria-label="Permalink to &quot;检索器&quot;">​</a></h3><p>检索器是一种便于模型查询的存储数据的方式，LangChain约定检索器组件至少有一个方法<code>get_relevant_texts</code>，这个方法接收查询字符串，返回一组文档。</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">from langchain.document_loaders import TextLoader</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.text_splitter import CharacterTextSplitter</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.vectorstores import FAISS</span></span>
<span class="line"><span style="color:#e1e4e8;">from langchain.embeddings import OpenAIEmbeddings</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">loader = TextLoader(&#39;../../../state_of_the_union.txt&#39;)</span></span>
<span class="line"><span style="color:#e1e4e8;">documents = loader.load()</span></span>
<span class="line"><span style="color:#e1e4e8;">text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)</span></span>
<span class="line"><span style="color:#e1e4e8;">texts = text_splitter.split_documents(documents)</span></span>
<span class="line"><span style="color:#e1e4e8;">embeddings = OpenAIEmbeddings()</span></span>
<span class="line"><span style="color:#e1e4e8;"></span></span>
<span class="line"><span style="color:#e1e4e8;">db = FAISS.from_documents(texts, embeddings)</span></span>
<span class="line"><span style="color:#e1e4e8;">retriever = db.as_retriever()</span></span>
<span class="line"><span style="color:#e1e4e8;">docs = retriever.get_relevant_documents(&quot;what did he say about ketanji brown jackson&quot;)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">from langchain.document_loaders import TextLoader</span></span>
<span class="line"><span style="color:#24292e;">from langchain.text_splitter import CharacterTextSplitter</span></span>
<span class="line"><span style="color:#24292e;">from langchain.vectorstores import FAISS</span></span>
<span class="line"><span style="color:#24292e;">from langchain.embeddings import OpenAIEmbeddings</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">loader = TextLoader(&#39;../../../state_of_the_union.txt&#39;)</span></span>
<span class="line"><span style="color:#24292e;">documents = loader.load()</span></span>
<span class="line"><span style="color:#24292e;">text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)</span></span>
<span class="line"><span style="color:#24292e;">texts = text_splitter.split_documents(documents)</span></span>
<span class="line"><span style="color:#24292e;">embeddings = OpenAIEmbeddings()</span></span>
<span class="line"><span style="color:#24292e;"></span></span>
<span class="line"><span style="color:#24292e;">db = FAISS.from_documents(texts, embeddings)</span></span>
<span class="line"><span style="color:#24292e;">retriever = db.as_retriever()</span></span>
<span class="line"><span style="color:#24292e;">docs = retriever.get_relevant_documents(&quot;what did he say about ketanji brown jackson&quot;)</span></span></code></pre></div><h2 id="_7-代理和链的区别" tabindex="-1">7 代理和链的区别 <a class="header-anchor" href="#_7-代理和链的区别" aria-label="Permalink to &quot;7 代理和链的区别&quot;">​</a></h2><p>代理组件和链组件的作用类似，它们都是用来调度业务流程，确定采取哪些行动以及按照何种顺序。不同的是链的执行流程是确定的，而代理则依赖于大语言模型来决定流程走向，比如我们之前写的询问北京明天应该穿什么衣服的例子。代理控制的行动，可以是任何支持输入输出的工具，比如搜索引擎、数据库，也可以是一个模型、一个链，甚至是另外一个代理。</p><p>我们通过数据流向看它们的区别：</p><p>简单应用：</p><p><img src="/assets/v2-5a97698192b2b03b89300699c4a75c25_1440w.878b6725.webp" alt="img"></p><p>链应用：</p><p><img src="/assets/v2-2ce4cce5d27b036cdd645d081698c26e_1440w.520cf966.webp" alt="img"></p><p>代理应用：</p><p><img src="/assets/v2-ad290ed2657b75d6def229a429038616_r.1eb9cf16.jpg" alt="img"></p><h1 id="十分钟做一个产品客服" tabindex="-1">十分钟做一个产品客服 <a class="header-anchor" href="#十分钟做一个产品客服" aria-label="Permalink to &quot;十分钟做一个产品客服&quot;">​</a></h1><h2 id="流程图" tabindex="-1">流程图 <a class="header-anchor" href="#流程图" aria-label="Permalink to &quot;流程图&quot;">​</a></h2><p>在这个过程中，LangChain应用接收两个<strong>输入</strong>，一个是自定义知识库，一个是用户输入。自定义知识库经过<strong>分割</strong>、<strong>嵌入</strong>之后存储到向量存储库，向量存储库支持语义检索，根据用户输入从长文档里<strong>检索</strong>出文本片段，提示模板将文本片段和用户输入合并成<strong>提示</strong>，传递给大语言模型，大语言模型<strong>推理</strong>出结果，经过<strong>解析</strong>后，<strong>输出</strong>最终结果。</p><p><img src="/assets/v2-7a99800b5bd593ad128f9f0780a1a8a0_1440w.ccd35454.webp" alt="img"></p><p>用到的所有组件如下：</p><table><thead><tr><th>组件</th><th>类型</th><th>子类型</th></tr></thead><tbody><tr><td>TextLoader</td><td>索引组件</td><td>文本加载器</td></tr><tr><td>CharacterTextSplitter</td><td>索引组件</td><td>文本分割器</td></tr><tr><td>ConversationalRetrievalChain</td><td>链组件</td><td>对话链</td></tr><tr><td>ChatOpenAI</td><td>模型组件</td><td>LLM</td></tr><tr><td>OpenAIEmbeddings</td><td>模型组件</td><td>文本嵌入模型</td></tr><tr><td>Chroma</td><td>索引组件</td><td>向量存储库</td></tr></tbody></table><h2 id="安装环境" tabindex="-1">安装环境 <a class="header-anchor" href="#安装环境" aria-label="Permalink to &quot;安装环境&quot;">​</a></h2><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">!pip install langchain</span></span>
<span class="line"><span style="color:#e1e4e8;">!pip install openai</span></span>
<span class="line"><span style="color:#e1e4e8;">!pip install chromadb</span></span>
<span class="line"><span style="color:#e1e4e8;">!pip install tiktoken</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">!pip install langchain</span></span>
<span class="line"><span style="color:#24292e;">!pip install openai</span></span>
<span class="line"><span style="color:#24292e;">!pip install chromadb</span></span>
<span class="line"><span style="color:#24292e;">!pip install tiktoken</span></span></code></pre></div><p>代码，略。</p></div></div></main><footer class="VPDocFooter" data-v-6b87e69f data-v-ef5dee53><!--[--><!--]--><div class="edit-info" data-v-ef5dee53><div class="edit-link" data-v-ef5dee53><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/mingriyingying/mingriyingying.github.io/blob/master/docs/articles/Algorithm/23LangChain/01LangChain入门.md" target="_blank" rel="noreferrer" data-v-ef5dee53><!--[--><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" class="edit-link-icon" aria-label="edit icon" data-v-ef5dee53><path d="M18,23H4c-1.7,0-3-1.3-3-3V6c0-1.7,1.3-3,3-3h7c0.6,0,1,0.4,1,1s-0.4,1-1,1H4C3.4,5,3,5.4,3,6v14c0,0.6,0.4,1,1,1h14c0.6,0,1-0.4,1-1v-7c0-0.6,0.4-1,1-1s1,0.4,1,1v7C21,21.7,19.7,23,18,23z"></path><path d="M8,17c-0.3,0-0.5-0.1-0.7-0.3C7,16.5,6.9,16.1,7,15.8l1-4c0-0.2,0.1-0.3,0.3-0.5l9.5-9.5c1.2-1.2,3.2-1.2,4.4,0c1.2,1.2,1.2,3.2,0,4.4l-9.5,9.5c-0.1,0.1-0.3,0.2-0.5,0.3l-4,1C8.2,17,8.1,17,8,17zM9.9,12.5l-0.5,2.1l2.1-0.5l9.3-9.3c0.4-0.4,0.4-1.1,0-1.6c-0.4-0.4-1.2-0.4-1.6,0l0,0L9.9,12.5z M18.5,2.5L18.5,2.5L18.5,2.5z"></path></svg> Edit this page on GitHub<!--]--></a></div><!----></div><!----></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"articles_algorithm_10白板推导系列_01介绍.md\":\"176ca1a2\",\"articles_algorithm_01python语法_工具_index.md\":\"8ad0cc38\",\"articles_algorithm_01python语法_工具_02np.array()和np.mat()区别.md\":\"20f996fb\",\"articles_algorithm_01python语法_工具_03python常用库.md\":\"8065203a\",\"about_index.md\":\"8e9b4f97\",\"articles_algorithm_01python语法_工具_10docx.md\":\"faf68671\",\"articles_algorithm_01python语法_工具_01python3语法.md\":\"6a181f84\",\"articles_algorithm_10白板推导系列_07指数族分布.md\":\"7e7e9f72\",\"articles_java_01java语法_10java读大数据量excel.md\":\"1a64b300\",\"articles_java_01java语法_10web前后端大文件上传和接收.md\":\"c9393c1d\",\"articles_algorithm_10白板推导系列_06支持向量机.md\":\"f6f8da89\",\"articles_java_01java语法_11java线程池的使用.md\":\"e5940b78\",\"articles_java_01java语法_12java正则化.md\":\"d96fb728\",\"articles_java_01java语法_index.md\":\"7829dfc3\",\"articles_java_02html_css_js_xml_index.md\":\"94de74a0\",\"articles_java_03javaweb基础tomcat servlet jsp_index.md\":\"a423dc3e\",\"articles_java_05maven_index.md\":\"0fc81f60\",\"articles_java_20mysql_index.md\":\"e283be17\",\"articles_java_22janusgraph_index.md\":\"82fee626\",\"articles_java_31java并发编程_index.md\":\"29d2febb\",\"articles_java_51springboot_00springboot.md\":\"9446f56a\",\"articles_java_51springboot_01freemarker模板.md\":\"35b979d5\",\"articles_java_51springboot_02i18n国际化.md\":\"14b59b8c\",\"articles_java_51springboot_03日志slf4j.md\":\"03ae1162\",\"articles_java_01java语法_10java读大数据量csv.md\":\"30452cef\",\"articles_java_51springboot_04缓存redis.md\":\"2503e11d\",\"articles_java_51springboot_05安全shiro.md\":\"b9311a8e\",\"articles_java_51springboot_05安全springsecurity.md\":\"830cd08b\",\"articles_java_51springboot_06分页pagehelper.md\":\"29b69393\",\"articles_java_51springboot_07任务 之 异步 定时 邮件.md\":\"ee4a3800\",\"articles_java_51springboot_10读文件.md\":\"d839210a\",\"articles_java_51springboot_11日志.md\":\"9b4f3776\",\"articles_java_51springboot_index.md\":\"197072b0\",\"articles_java_53arthus_index.md\":\"cff324b3\",\"articles_algorithm_10白板推导系列_14lds线性动态系统.md\":\"fb943bcc\",\"articles_java_60kafka_index.md\":\"c1e239b3\",\"articles_java_65redis_01redis基础.md\":\"b1fd6eba\",\"articles_java_65redis_02redis集群搭建.md\":\"5bf43506\",\"articles_java_65redis_index.md\":\"e0ab5a08\",\"articles_java_65vue_02vue3实战.md\":\"7edccd0e\",\"articles_java_65vue_index.md\":\"41626696\",\"articles_java_66jenkins_index.md\":\"0874217a\",\"articles_ops_docker_docker教程.md\":\"8218b92d\",\"articles_ops_docker_index.md\":\"4474881d\",\"articles_ops_git_index.md\":\"7fc7cfa2\",\"articles_ops_linux_01linux教程.md\":\"417340bc\",\"articles_algorithm_10白板推导系列_15particlefilter粒子滤波.md\":\"7cb194f0\",\"articles_ops_linux_02shell脚本.md\":\"136dd64b\",\"articles_ops_linux_02shell脚本之服务启停脚本.md\":\"a67f47dd\",\"articles_ops_linux_03重要命令.md\":\"f2bfd1d2\",\"articles_ops_linux_04linux性能监控.md\":\"d53800ef\",\"articles_ops_linux_index.md\":\"8dd7462a\",\"articles_ops_linux_linux开发环境准备.md\":\"b613d8f2\",\"articles_ops_nginx_01nginx.md\":\"7939d723\",\"articles_ops_nginx_index.md\":\"4bd4d3f3\",\"articles_ops_k8s_untitled.md\":\"f71d8ec9\",\"articles_ops_k8s_index.md\":\"bb4b7c97\",\"articles_ops_k8s_k8s安装文档.md\":\"26fd6f3a\",\"articles_ops_k8s_k8s教程.md\":\"7510ec7f\",\"articles_vitepress_01vitepress_github搭建个人博客.md\":\"2a0101d0\",\"articles_vitepress_02一键部署.md\":\"0069c9ec\",\"articles_vitepress_03新环境如何配置.md\":\"9a0f686b\",\"articles_vitepress_03自动生成菜单.md\":\"ffb1ebbd\",\"articles_vitepress_04利用github actions自动部署.md\":\"c9229db1\",\"articles_vitepress_05支持latex语法(数学公式).md\":\"0e26ce9f\",\"articles_vitepress_06自定义首页_模板.md\":\"90578ceb\",\"articles_windows_02latex与文献检索.md\":\"a2d2ba54\",\"articles_windows_13tvbox.md\":\"6be49e05\",\"articles_windows_14typora.md\":\"5403befa\",\"articles_windows_16欧拉系统安装gpu驱动.md\":\"166785a3\",\"articles_windows_index.md\":\"1f3bd6a8\",\"index.md\":\"766b2e61\",\"articles_algorithm_12llm_22mt0.md\":\"551858fe\",\"articles_algorithm_10白板推导系列_22nn.md\":\"22f28813\",\"articles_algorithm_10白板推导系列_24approinference.md\":\"813ae68b\",\"articles_algorithm_10白板推导系列_index.md\":\"7e03b24d\",\"articles_algorithm_11强化学习_01强化学习环境.md\":\"c31ab779\",\"articles_algorithm_10白板推导系列_20rbm.md\":\"1ee68cc8\",\"articles_algorithm_11强化学习_01深度强化学习-李宏毅.md\":\"a341f12d\",\"articles_algorithm_12llm_00ai前期发展2016.md\":\"8173da53\",\"articles_algorithm_12llm_01seq2seq和attention.md\":\"695f114e\",\"articles_algorithm_12llm_02word2vec.md\":\"9c71c14b\",\"articles_algorithm_12llm_03transformerxl.md\":\"667ebb21\",\"articles_algorithm_12llm_03transformer详解.md\":\"7f6d7a1c\",\"articles_algorithm_12llm_04bert1进化史.md\":\"f3a860e9\",\"articles_algorithm_12llm_04学习分词技术subword.md\":\"54b4c3ac\",\"articles_algorithm_12llm_05gpt01论文.md\":\"c9cfbc8e\",\"articles_algorithm_12llm_05gpt02模型.md\":\"b5e9e6bb\",\"articles_algorithm_12llm_06mtdnn.md\":\"b2ffb8a1\",\"articles_java_52springcloud_index.md\":\"f8f5dd71\",\"articles_algorithm_12llm_06xlnet.md\":\"fb1dfcb1\",\"articles_algorithm_12llm_07roberta.md\":\"2f23c4de\",\"articles_algorithm_12llm_08albert.md\":\"d49f27e8\",\"articles_algorithm_12llm_09electra.md\":\"2841c295\",\"articles_algorithm_10白板推导系列_05降维.md\":\"33c05daa\",\"articles_algorithm_12llm_11t5.md\":\"916e0995\",\"articles_windows_10idea.md\":\"9f3f4681\",\"articles_algorithm_12llm_11学习attention mask.md\":\"80a8ce48\",\"articles_algorithm_12llm_12gpt3.md\":\"b3edd24a\",\"articles_algorithm_12llm_13flan.md\":\"99cd2b08\",\"articles_algorithm_12llm_14t0.md\":\"9df3b4a0\",\"articles_algorithm_12llm_15lamda.md\":\"e73801e1\",\"articles_algorithm_12llm_16instructgpt.md\":\"471d2758\",\"articles_algorithm_12llm_16opt.md\":\"19f3032d\",\"articles_algorithm_12llm_17gpt-neox-20b.md\":\"41089120\",\"articles_algorithm_12llm_18ul2.md\":\"9d19979f\",\"articles_algorithm_12llm_19palm.md\":\"9eb4cf02\",\"articles_algorithm_12llm_21flan-palm.md\":\"fe9bb99c\",\"articles_algorithm_12llm_21flan-t5.md\":\"9f2b4888\",\"articles_algorithm_12llm_22bloom.md\":\"6a282fdc\",\"articles_algorithm_12llm_22chatgpt.md\":\"2553cf34\",\"articles_algorithm_12llm_22opt-iml.md\":\"40f174c0\",\"articles_algorithm_12llm_23gpt4.md\":\"059701c7\",\"articles_algorithm_12llm_23llama.md\":\"ec4b68cf\",\"articles_algorithm_12llm_25stanford alpaca.md\":\"4c9a3e8e\",\"articles_algorithm_12llm_25vicuna.md\":\"b469ea31\",\"articles_algorithm_12llm_26llama2.md\":\"929db705\",\"articles_algorithm_12llm_26llama2中的技术.md\":\"ce8e92d2\",\"articles_algorithm_12llm_27interlm.md\":\"b03f2498\",\"articles_algorithm_12llm_28tigerbot.md\":\"4738fa69\",\"articles_algorithm_12llm_39qwen.md\":\"c4bdbf93\",\"articles_algorithm_10白板推导系列_03线性回归.md\":\"e23a1c36\",\"articles_algorithm_12llm_41mbart.md\":\"71964096\",\"articles_algorithm_12llm_42nllb-200.md\":\"5f3d94c6\",\"articles_algorithm_12llm_43madlad-400.md\":\"c7962fe0\",\"articles_algorithm_12llm_index.md\":\"1587e218\",\"articles_algorithm_12机器学习笔记_00算法性能度量.md\":\"7e1b17b0\",\"articles_algorithm_12机器学习笔记_01概述.md\":\"8303897d\",\"articles_algorithm_12机器学习笔记_02梯度消失.md\":\"629ea8c1\",\"articles_algorithm_10白板推导系列_18贝叶斯线性回归.md\":\"93509b41\",\"articles_java_30设计模式_index.md\":\"2036be1e\",\"articles_algorithm_12机器学习笔记_03逻辑回归.md\":\"3ea2e8bf\",\"articles_algorithm_12llm_00多模态.md\":\"9ba3d932\",\"articles_algorithm_12机器学习笔记_04gbdt.md\":\"a2f54a46\",\"articles_algorithm_12llm_00综述.md\":\"9f55c7e9\",\"articles_algorithm_12llm_01prtnet.md\":\"66138bab\",\"articles_algorithm_12机器学习笔记_05adam.md\":\"6fc614d2\",\"articles_algorithm_12机器学习笔记_10调参指南.md\":\"8cfbae47\",\"articles_algorithm_12机器学习笔记_11过拟合问题.md\":\"1b068c55\",\"articles_algorithm_12机器学习笔记_12bagging和随机森林.md\":\"25cdf836\",\"articles_algorithm_12机器学习笔记_13adaboost.md\":\"e052cc8e\",\"articles_algorithm_12机器学习笔记_14lightgbm.md\":\"f59e6c64\",\"articles_algorithm_12机器学习笔记_15xgboost.md\":\"1926e6b4\",\"articles_algorithm_12机器学习笔记_16lightgbm.md\":\"b9ec8433\",\"articles_algorithm_12机器学习笔记_17catboost.md\":\"22bab25d\",\"articles_algorithm_12机器学习笔记_index.md\":\"f281a514\",\"articles_algorithm_21模型部署_00调研模型工业化部署.md\":\"5f1fa797\",\"articles_algorithm_21模型部署_02fastapi.md\":\"77179108\",\"articles_algorithm_21模型部署_03fasttransformer.md\":\"fb4e07ac\",\"articles_algorithm_21模型部署_index.md\":\"945f856d\",\"articles_algorithm_22模型训练和微调_00项目学习.md\":\"a303eabc\",\"articles_algorithm_22模型训练和微调_01并行训练.md\":\"1816afc0\",\"articles_algorithm_22模型训练和微调_02模型微调.md\":\"a343f965\",\"articles_algorithm_22模型训练和微调_03chatglm微调学习.md\":\"e385334f\",\"articles_algorithm_22模型训练和微调_04deepseepd rlhf.md\":\"78fab5b2\",\"articles_algorithm_22模型训练和微调_index.md\":\"6a29de37\",\"articles_algorithm_23langchain_00基于大语言模型知识问答应用落地实践.md\":\"19517067\",\"articles_algorithm_23langchain_01langchain入门.md\":\"f19d9991\",\"articles_algorithm_23langchain_02工具总结.md\":\"a1b146b5\",\"articles_algorithm_23langchain_03langchain检索.md\":\"74a116d1\",\"articles_blog_01huggingface入门.md\":\"abe31d86\",\"articles_blog_01指令.md\":\"3e35021a\",\"articles_blog_index.md\":\"9250c279\",\"articles_java_01java语法_02java8实战.md\":\"466ba27a\",\"articles_algorithm_12llm_04bert2详解.md\":\"0968ac11\",\"articles_algorithm_12llm_10t5.md\":\"625b4faf\",\"articles_algorithm_21模型部署_02gradio.md\":\"8a053f52\",\"articles_algorithm_22模型训练和微调_10各种包如何用.md\":\"ed1c9aa1\",\"articles_java_65vue_01vue3_ts语法.md\":\"0b446e12\",\"articles_algorithm_11强化学习_index.md\":\"61535b70\",\"articles_vitepress_07文档项目仓库分离.md\":\"1ef6be6a\",\"articles_vitepress_index.md\":\"a289bad2\",\"articles_algorithm_12llm_00llm发展2017-2013.md\":\"7ab55f38\",\"articles_windows_01常用软件.md\":\"c9842742\",\"articles_windows_15miniconda_pycharm_cuda.md\":\"821dea1a\",\"articles_algorithm_10白板推导系列_02高斯分布.md\":\"76df0539\",\"articles_algorithm_10白板推导系列_17高斯网络.md\":\"b629dbd5\",\"articles_algorithm_10白板推导系列_04线性分类.md\":\"19875900\",\"articles_algorithm_10白板推导系列_19高斯过程回归.md\":\"d1425ccf\",\"articles_java_61elasticsearch_index.md\":\"4386ad02\",\"articles_algorithm_10白板推导系列_12mcmc.md\":\"ceebe04f\",\"articles_algorithm_12机器学习笔记_14adboost.md\":\"8df17e03\",\"articles_algorithm_23langchain_index.md\":\"38e8d089\",\"articles_algorithm_10白板推导系列_10gmm.md\":\"16b4ef85\",\"articles_algorithm_10白板推导系列_16crf.md\":\"606f5a36\",\"articles_algorithm_10白板推导系列_11vi变分推断.md\":\"7521e131\",\"articles_algorithm_10白板推导系列_21spectral谱聚类.md\":\"06fd562a\",\"articles_algorithm_10白板推导系列_23partitionfunction.md\":\"5076e96d\",\"articles_algorithm_10白板推导系列_08概率图模型.md\":\"1a606efa\",\"articles_algorithm_10白板推导系列_09em.md\":\"21c1515b\",\"articles_algorithm_10白板推导系列_13hmm.md\":\"61763bcd\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"明日盈盈\",\"titleTemplate\":\"Make each day count, Make learning a habit.\",\"description\":\"一只程序猿\",\"base\":\"/\",\"head\":[],\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"Home\",\"nav\":[{\"text\":\"Algorithm\",\"items\":[{\"text\":\"01python语法&工具\",\"link\":\"/articles/Algorithm/01python语法&工具/\"},{\"text\":\"10白板推导系列\",\"link\":\"/articles/Algorithm/10白板推导系列/\"},{\"text\":\"11强化学习\",\"link\":\"/articles/Algorithm/11强化学习/\"},{\"text\":\"12LLM\",\"link\":\"/articles/Algorithm/12LLM/\"},{\"text\":\"12机器学习笔记\",\"link\":\"/articles/Algorithm/12机器学习笔记/\"},{\"text\":\"21模型部署\",\"link\":\"/articles/Algorithm/21模型部署/\"},{\"text\":\"22模型训练和微调\",\"link\":\"/articles/Algorithm/22模型训练和微调/\"},{\"text\":\"23LangChain\",\"link\":\"/articles/Algorithm/23LangChain/\"}]},{\"text\":\"Blog\",\"link\":\"/articles/Blog/\"},{\"text\":\"Java\",\"items\":[{\"text\":\"01Java语法\",\"link\":\"/articles/Java/01Java语法/\"},{\"text\":\"02HTML+CSS+JS+XML\",\"link\":\"/articles/Java/02HTML+CSS+JS+XML/\"},{\"text\":\"03JavaWeb基础tomcat servlet jsp\",\"link\":\"/articles/Java/03JavaWeb基础tomcat servlet jsp/\"},{\"text\":\"05Maven\",\"link\":\"/articles/Java/05Maven/\"},{\"text\":\"20mysql\",\"link\":\"/articles/Java/20mysql/\"},{\"text\":\"22JanusGraph\",\"link\":\"/articles/Java/22JanusGraph/\"},{\"text\":\"30设计模式\",\"link\":\"/articles/Java/30设计模式/\"},{\"text\":\"31Java并发编程\",\"link\":\"/articles/Java/31Java并发编程/\"},{\"text\":\"51SpringBoot\",\"link\":\"/articles/Java/51SpringBoot/\"},{\"text\":\"52SpringCloud\",\"link\":\"/articles/Java/52SpringCloud/\"},{\"text\":\"53Arthus\",\"link\":\"/articles/Java/53Arthus/\"},{\"text\":\"60kafka\",\"link\":\"/articles/Java/60kafka/\"},{\"text\":\"61ElasticSearch\",\"link\":\"/articles/Java/61ElasticSearch/\"},{\"text\":\"65redis\",\"link\":\"/articles/Java/65redis/\"},{\"text\":\"65vue\",\"link\":\"/articles/Java/65vue/\"},{\"text\":\"66jenkins\",\"link\":\"/articles/Java/66jenkins/\"}]},{\"text\":\"Ops\",\"items\":[{\"text\":\"Docker\",\"link\":\"/articles/Ops/Docker/\"},{\"text\":\"Git\",\"link\":\"/articles/Ops/Git/\"},{\"text\":\"Linux\",\"link\":\"/articles/Ops/Linux/\"},{\"text\":\"Nginx\",\"link\":\"/articles/Ops/Nginx/\"},{\"text\":\"k8s\",\"link\":\"/articles/Ops/k8s/\"}]},{\"text\":\"VitePress\",\"link\":\"/articles/VitePress/\"},{\"text\":\"windows\",\"link\":\"/articles/windows/\"}],\"sidebar\":{\"/articles/Algorithm/01python语法&工具\":[{\"text\":\"01python语法&工具\",\"items\":[{\"text\":\"01python3语法\",\"link\":\"/articles/Algorithm/01python语法&工具/01python3语法.md\"},{\"text\":\"02np.array()和np.mat()区别\",\"link\":\"/articles/Algorithm/01python语法&工具/02np.array()和np.mat()区别.md\"},{\"text\":\"03python常用库\",\"link\":\"/articles/Algorithm/01python语法&工具/03python常用库.md\"},{\"text\":\"10docx\",\"link\":\"/articles/Algorithm/01python语法&工具/10docx.md\"}]}],\"/articles/Algorithm/10白板推导系列\":[{\"text\":\"10白板推导系列\",\"items\":[{\"text\":\"01介绍\",\"link\":\"/articles/Algorithm/10白板推导系列/01介绍.md\"},{\"text\":\"02高斯分布\",\"link\":\"/articles/Algorithm/10白板推导系列/02高斯分布.md\"},{\"text\":\"03线性回归\",\"link\":\"/articles/Algorithm/10白板推导系列/03线性回归.md\"},{\"text\":\"04线性分类\",\"link\":\"/articles/Algorithm/10白板推导系列/04线性分类.md\"},{\"text\":\"05降维\",\"link\":\"/articles/Algorithm/10白板推导系列/05降维.md\"},{\"text\":\"06支持向量机\",\"link\":\"/articles/Algorithm/10白板推导系列/06支持向量机.md\"},{\"text\":\"07指数族分布\",\"link\":\"/articles/Algorithm/10白板推导系列/07指数族分布.md\"},{\"text\":\"08概率图模型\",\"link\":\"/articles/Algorithm/10白板推导系列/08概率图模型.md\"},{\"text\":\"09EM\",\"link\":\"/articles/Algorithm/10白板推导系列/09EM.md\"},{\"text\":\"10GMM\",\"link\":\"/articles/Algorithm/10白板推导系列/10GMM.md\"},{\"text\":\"11VI变分推断\",\"link\":\"/articles/Algorithm/10白板推导系列/11VI变分推断.md\"},{\"text\":\"12MCMC\",\"link\":\"/articles/Algorithm/10白板推导系列/12MCMC.md\"},{\"text\":\"13HMM\",\"link\":\"/articles/Algorithm/10白板推导系列/13HMM.md\"},{\"text\":\"14LDS线性动态系统\",\"link\":\"/articles/Algorithm/10白板推导系列/14LDS线性动态系统.md\"},{\"text\":\"15particleFilter粒子滤波\",\"link\":\"/articles/Algorithm/10白板推导系列/15particleFilter粒子滤波.md\"},{\"text\":\"16CRF\",\"link\":\"/articles/Algorithm/10白板推导系列/16CRF.md\"},{\"text\":\"17高斯网络\",\"link\":\"/articles/Algorithm/10白板推导系列/17高斯网络.md\"},{\"text\":\"18贝叶斯线性回归\",\"link\":\"/articles/Algorithm/10白板推导系列/18贝叶斯线性回归.md\"},{\"text\":\"19高斯过程回归\",\"link\":\"/articles/Algorithm/10白板推导系列/19高斯过程回归.md\"},{\"text\":\"20RBM\",\"link\":\"/articles/Algorithm/10白板推导系列/20RBM.md\"},{\"text\":\"21Spectral谱聚类\",\"link\":\"/articles/Algorithm/10白板推导系列/21Spectral谱聚类.md\"},{\"text\":\"22NN\",\"link\":\"/articles/Algorithm/10白板推导系列/22NN.md\"},{\"text\":\"23PartitionFunction\",\"link\":\"/articles/Algorithm/10白板推导系列/23PartitionFunction.md\"},{\"text\":\"24ApproInference\",\"link\":\"/articles/Algorithm/10白板推导系列/24ApproInference.md\"}]}],\"/articles/Algorithm/11强化学习\":[{\"text\":\"11强化学习\",\"items\":[{\"text\":\"01强化学习环境\",\"link\":\"/articles/Algorithm/11强化学习/01强化学习环境.md\"},{\"text\":\"01深度强化学习-李宏毅\",\"link\":\"/articles/Algorithm/11强化学习/01深度强化学习-李宏毅.md\"}]}],\"/articles/Algorithm/12LLM\":[{\"text\":\"12LLM\",\"items\":[{\"text\":\"00AI前期发展2016\",\"link\":\"/articles/Algorithm/12LLM/00AI前期发展2016.md\"},{\"text\":\"00LLM发展2017-2013\",\"link\":\"/articles/Algorithm/12LLM/00LLM发展2017-2013.md\"},{\"text\":\"00多模态\",\"link\":\"/articles/Algorithm/12LLM/00多模态.md\"},{\"text\":\"00综述\",\"link\":\"/articles/Algorithm/12LLM/00综述.md\"},{\"text\":\"01PrtNet\",\"link\":\"/articles/Algorithm/12LLM/01PrtNet.md\"},{\"text\":\"01seq2seq和Attention\",\"link\":\"/articles/Algorithm/12LLM/01seq2seq和Attention.md\"},{\"text\":\"02word2Vec\",\"link\":\"/articles/Algorithm/12LLM/02word2Vec.md\"},{\"text\":\"03TransformerXL\",\"link\":\"/articles/Algorithm/12LLM/03TransformerXL.md\"},{\"text\":\"03Transformer详解\",\"link\":\"/articles/Algorithm/12LLM/03Transformer详解.md\"},{\"text\":\"04bert1进化史\",\"link\":\"/articles/Algorithm/12LLM/04bert1进化史.md\"},{\"text\":\"04bert2详解\",\"link\":\"/articles/Algorithm/12LLM/04bert2详解.md\"},{\"text\":\"04学习分词技术Subword\",\"link\":\"/articles/Algorithm/12LLM/04学习分词技术Subword.md\"},{\"text\":\"05GPT01论文\",\"link\":\"/articles/Algorithm/12LLM/05GPT01论文.md\"},{\"text\":\"05GPT02模型\",\"link\":\"/articles/Algorithm/12LLM/05GPT02模型.md\"},{\"text\":\"06MTDNN\",\"link\":\"/articles/Algorithm/12LLM/06MTDNN.md\"},{\"text\":\"06XLNet\",\"link\":\"/articles/Algorithm/12LLM/06XLNet.md\"},{\"text\":\"07RoBERTa\",\"link\":\"/articles/Algorithm/12LLM/07RoBERTa.md\"},{\"text\":\"08ALBERT\",\"link\":\"/articles/Algorithm/12LLM/08ALBERT.md\"},{\"text\":\"09ELECTRA\",\"link\":\"/articles/Algorithm/12LLM/09ELECTRA.md\"},{\"text\":\"10T5\",\"link\":\"/articles/Algorithm/12LLM/10T5.md\"},{\"text\":\"11T5\",\"link\":\"/articles/Algorithm/12LLM/11T5.md\"},{\"text\":\"11学习attention mask\",\"link\":\"/articles/Algorithm/12LLM/11学习attention mask.md\"},{\"text\":\"12GPT3\",\"link\":\"/articles/Algorithm/12LLM/12GPT3.md\"},{\"text\":\"13FLAN\",\"link\":\"/articles/Algorithm/12LLM/13FLAN.md\"},{\"text\":\"14T0\",\"link\":\"/articles/Algorithm/12LLM/14T0.md\"},{\"text\":\"15LaMDA\",\"link\":\"/articles/Algorithm/12LLM/15LaMDA.md\"},{\"text\":\"16InstructGPT\",\"link\":\"/articles/Algorithm/12LLM/16InstructGPT.md\"},{\"text\":\"16OPT\",\"link\":\"/articles/Algorithm/12LLM/16OPT.md\"},{\"text\":\"17GPT-NeoX-20B\",\"link\":\"/articles/Algorithm/12LLM/17GPT-NeoX-20B.md\"},{\"text\":\"18UL2\",\"link\":\"/articles/Algorithm/12LLM/18UL2.md\"},{\"text\":\"19PaLM\",\"link\":\"/articles/Algorithm/12LLM/19PaLM.md\"},{\"text\":\"21Flan-PaLM\",\"link\":\"/articles/Algorithm/12LLM/21Flan-PaLM.md\"},{\"text\":\"21Flan-T5\",\"link\":\"/articles/Algorithm/12LLM/21Flan-T5.md\"},{\"text\":\"22BLOOM\",\"link\":\"/articles/Algorithm/12LLM/22BLOOM.md\"},{\"text\":\"22ChatGPT\",\"link\":\"/articles/Algorithm/12LLM/22ChatGPT.md\"},{\"text\":\"22OPT-IML\",\"link\":\"/articles/Algorithm/12LLM/22OPT-IML.md\"},{\"text\":\"22mT0\",\"link\":\"/articles/Algorithm/12LLM/22mT0.md\"},{\"text\":\"23GPT4\",\"link\":\"/articles/Algorithm/12LLM/23GPT4.md\"},{\"text\":\"23LLaMA\",\"link\":\"/articles/Algorithm/12LLM/23LLaMA.md\"},{\"text\":\"25Stanford Alpaca\",\"link\":\"/articles/Algorithm/12LLM/25Stanford Alpaca.md\"},{\"text\":\"25Vicuna\",\"link\":\"/articles/Algorithm/12LLM/25Vicuna.md\"},{\"text\":\"26LLaMA2\",\"link\":\"/articles/Algorithm/12LLM/26LLaMA2.md\"},{\"text\":\"26LLaMA2中的技术\",\"link\":\"/articles/Algorithm/12LLM/26LLaMA2中的技术.md\"},{\"text\":\"27InterLM\",\"link\":\"/articles/Algorithm/12LLM/27InterLM.md\"},{\"text\":\"28Tigerbot\",\"link\":\"/articles/Algorithm/12LLM/28Tigerbot.md\"},{\"text\":\"39Qwen\",\"link\":\"/articles/Algorithm/12LLM/39Qwen.md\"},{\"text\":\"41mBART\",\"link\":\"/articles/Algorithm/12LLM/41mBART.md\"},{\"text\":\"42NLLB-200\",\"link\":\"/articles/Algorithm/12LLM/42NLLB-200.md\"},{\"text\":\"43MADLAD-400\",\"link\":\"/articles/Algorithm/12LLM/43MADLAD-400.md\"}]}],\"/articles/Algorithm/12机器学习笔记\":[{\"text\":\"12机器学习笔记\",\"items\":[{\"text\":\"00算法性能度量\",\"link\":\"/articles/Algorithm/12机器学习笔记/00算法性能度量.md\"},{\"text\":\"01概述\",\"link\":\"/articles/Algorithm/12机器学习笔记/01概述.md\"},{\"text\":\"02梯度消失\",\"link\":\"/articles/Algorithm/12机器学习笔记/02梯度消失.md\"},{\"text\":\"03逻辑回归\",\"link\":\"/articles/Algorithm/12机器学习笔记/03逻辑回归.md\"},{\"text\":\"04GBDT\",\"link\":\"/articles/Algorithm/12机器学习笔记/04GBDT.md\"},{\"text\":\"05Adam\",\"link\":\"/articles/Algorithm/12机器学习笔记/05Adam.md\"},{\"text\":\"10调参指南\",\"link\":\"/articles/Algorithm/12机器学习笔记/10调参指南.md\"},{\"text\":\"11过拟合问题\",\"link\":\"/articles/Algorithm/12机器学习笔记/11过拟合问题.md\"},{\"text\":\"12bagging和随机森林\",\"link\":\"/articles/Algorithm/12机器学习笔记/12bagging和随机森林.md\"},{\"text\":\"13Adaboost\",\"link\":\"/articles/Algorithm/12机器学习笔记/13Adaboost.md\"},{\"text\":\"14Adboost\",\"link\":\"/articles/Algorithm/12机器学习笔记/14Adboost.md\"},{\"text\":\"14LightGBM\",\"link\":\"/articles/Algorithm/12机器学习笔记/14LightGBM.md\"},{\"text\":\"15XGBoost\",\"link\":\"/articles/Algorithm/12机器学习笔记/15XGBoost.md\"},{\"text\":\"16Lightgbm\",\"link\":\"/articles/Algorithm/12机器学习笔记/16Lightgbm.md\"},{\"text\":\"17catboost\",\"link\":\"/articles/Algorithm/12机器学习笔记/17catboost.md\"}]}],\"/articles/Algorithm/21模型部署\":[{\"text\":\"21模型部署\",\"items\":[{\"text\":\"00调研模型工业化部署\",\"link\":\"/articles/Algorithm/21模型部署/00调研模型工业化部署.md\"},{\"text\":\"02FastApi\",\"link\":\"/articles/Algorithm/21模型部署/02FastApi.md\"},{\"text\":\"02Gradio\",\"link\":\"/articles/Algorithm/21模型部署/02Gradio.md\"},{\"text\":\"03FastTransformer\",\"link\":\"/articles/Algorithm/21模型部署/03FastTransformer.md\"}]}],\"/articles/Algorithm/22模型训练和微调\":[{\"text\":\"22模型训练和微调\",\"items\":[{\"text\":\"00项目学习\",\"link\":\"/articles/Algorithm/22模型训练和微调/00项目学习.md\"},{\"text\":\"01并行训练\",\"link\":\"/articles/Algorithm/22模型训练和微调/01并行训练.md\"},{\"text\":\"02模型微调\",\"link\":\"/articles/Algorithm/22模型训练和微调/02模型微调.md\"},{\"text\":\"03ChatGLM微调学习\",\"link\":\"/articles/Algorithm/22模型训练和微调/03ChatGLM微调学习.md\"},{\"text\":\"04DeepSeepd RLHF\",\"link\":\"/articles/Algorithm/22模型训练和微调/04DeepSeepd RLHF.md\"},{\"text\":\"10各种包如何用\",\"link\":\"/articles/Algorithm/22模型训练和微调/10各种包如何用.md\"}]}],\"/articles/Algorithm/23LangChain\":[{\"text\":\"23LangChain\",\"items\":[{\"text\":\"00基于大语言模型知识问答应用落地实践\",\"link\":\"/articles/Algorithm/23LangChain/00基于大语言模型知识问答应用落地实践.md\"},{\"text\":\"01LangChain入门\",\"link\":\"/articles/Algorithm/23LangChain/01LangChain入门.md\"},{\"text\":\"02工具总结\",\"link\":\"/articles/Algorithm/23LangChain/02工具总结.md\"},{\"text\":\"03LangChain检索\",\"link\":\"/articles/Algorithm/23LangChain/03LangChain检索.md\"}]}],\"/articles/Blog\":[{\"text\":\"Blog\",\"items\":[{\"text\":\"01HuggingFace入门\",\"link\":\"/articles/Blog/01HuggingFace入门.md\"},{\"text\":\"01指令\",\"link\":\"/articles/Blog/01指令.md\"}]}],\"/articles/Java/01Java语法\":[{\"text\":\"01Java语法\",\"items\":[{\"text\":\"02Java8实战\",\"link\":\"/articles/Java/01Java语法/02Java8实战.md\"},{\"text\":\"10Java读大数据量csv\",\"link\":\"/articles/Java/01Java语法/10Java读大数据量csv.md\"},{\"text\":\"10Java读大数据量excel\",\"link\":\"/articles/Java/01Java语法/10Java读大数据量excel.md\"},{\"text\":\"10Web前后端大文件上传和接收\",\"link\":\"/articles/Java/01Java语法/10Web前后端大文件上传和接收.md\"},{\"text\":\"11Java线程池的使用\",\"link\":\"/articles/Java/01Java语法/11Java线程池的使用.md\"},{\"text\":\"12Java正则化\",\"link\":\"/articles/Java/01Java语法/12Java正则化.md\"}]}],\"/articles/Java/51SpringBoot\":[{\"text\":\"51SpringBoot\",\"items\":[{\"text\":\"00SpringBoot\",\"link\":\"/articles/Java/51SpringBoot/00SpringBoot.md\"},{\"text\":\"01Freemarker模板\",\"link\":\"/articles/Java/51SpringBoot/01Freemarker模板.md\"},{\"text\":\"02i18n国际化\",\"link\":\"/articles/Java/51SpringBoot/02i18n国际化.md\"},{\"text\":\"03日志SLF4J\",\"link\":\"/articles/Java/51SpringBoot/03日志SLF4J.md\"},{\"text\":\"04缓存Redis\",\"link\":\"/articles/Java/51SpringBoot/04缓存Redis.md\"},{\"text\":\"05安全Shiro\",\"link\":\"/articles/Java/51SpringBoot/05安全Shiro.md\"},{\"text\":\"05安全SpringSecurity\",\"link\":\"/articles/Java/51SpringBoot/05安全SpringSecurity.md\"},{\"text\":\"06分页PageHelper\",\"link\":\"/articles/Java/51SpringBoot/06分页PageHelper.md\"},{\"text\":\"07任务 之 异步 定时 邮件\",\"link\":\"/articles/Java/51SpringBoot/07任务 之 异步 定时 邮件.md\"},{\"text\":\"10读文件\",\"link\":\"/articles/Java/51SpringBoot/10读文件.md\"},{\"text\":\"11日志\",\"link\":\"/articles/Java/51SpringBoot/11日志.md\"}]}],\"/articles/Java/65redis\":[{\"text\":\"65redis\",\"items\":[{\"text\":\"01redis基础\",\"link\":\"/articles/Java/65redis/01redis基础.md\"},{\"text\":\"02redis集群搭建\",\"link\":\"/articles/Java/65redis/02redis集群搭建.md\"}]}],\"/articles/Java/65vue\":[{\"text\":\"65vue\",\"items\":[{\"text\":\"01vue3+ts语法\",\"link\":\"/articles/Java/65vue/01vue3+ts语法.md\"},{\"text\":\"02vue3实战\",\"link\":\"/articles/Java/65vue/02vue3实战.md\"}]}],\"/articles/Ops/Docker\":[{\"text\":\"Docker\",\"items\":[{\"text\":\"docker教程\",\"link\":\"/articles/Ops/Docker/docker教程.md\"}]}],\"/articles/Ops/Linux\":[{\"text\":\"Linux\",\"items\":[{\"text\":\"01linux教程\",\"link\":\"/articles/Ops/Linux/01linux教程.md\"},{\"text\":\"02Shell脚本\",\"link\":\"/articles/Ops/Linux/02Shell脚本.md\"},{\"text\":\"02Shell脚本之服务启停脚本\",\"link\":\"/articles/Ops/Linux/02Shell脚本之服务启停脚本.md\"},{\"text\":\"03重要命令\",\"link\":\"/articles/Ops/Linux/03重要命令.md\"},{\"text\":\"04Linux性能监控\",\"link\":\"/articles/Ops/Linux/04Linux性能监控.md\"},{\"text\":\"linux开发环境准备\",\"link\":\"/articles/Ops/Linux/linux开发环境准备.md\"}]}],\"/articles/Ops/Nginx\":[{\"text\":\"Nginx\",\"items\":[{\"text\":\"01Nginx\",\"link\":\"/articles/Ops/Nginx/01Nginx.md\"}]}],\"/articles/Ops/k8s\":[{\"text\":\"k8s\",\"items\":[{\"text\":\"Untitled\",\"link\":\"/articles/Ops/k8s/Untitled.md\"},{\"text\":\"k8s安装文档\",\"link\":\"/articles/Ops/k8s/k8s安装文档.md\"},{\"text\":\"k8s教程\",\"link\":\"/articles/Ops/k8s/k8s教程.md\"}]}],\"/articles/VitePress\":[{\"text\":\"VitePress\",\"items\":[{\"text\":\"01VitePress+Github搭建个人博客\",\"link\":\"/articles/VitePress/01VitePress+Github搭建个人博客.md\"},{\"text\":\"02一键部署\",\"link\":\"/articles/VitePress/02一键部署.md\"},{\"text\":\"03新环境如何配置\",\"link\":\"/articles/VitePress/03新环境如何配置.md\"},{\"text\":\"03自动生成菜单\",\"link\":\"/articles/VitePress/03自动生成菜单.md\"},{\"text\":\"04利用Github Actions自动部署\",\"link\":\"/articles/VitePress/04利用Github Actions自动部署.md\"},{\"text\":\"05支持Latex语法(数学公式)\",\"link\":\"/articles/VitePress/05支持Latex语法(数学公式).md\"},{\"text\":\"06自定义首页&模板\",\"link\":\"/articles/VitePress/06自定义首页&模板.md\"},{\"text\":\"07文档项目仓库分离\",\"link\":\"/articles/VitePress/07文档项目仓库分离.md\"}]}],\"/articles/windows\":[{\"text\":\"windows\",\"items\":[{\"text\":\"01常用软件\",\"link\":\"/articles/windows/01常用软件.md\"},{\"text\":\"02Latex与文献检索\",\"link\":\"/articles/windows/02Latex与文献检索.md\"},{\"text\":\"10IDEA\",\"link\":\"/articles/windows/10IDEA.md\"},{\"text\":\"13tvbox\",\"link\":\"/articles/windows/13tvbox.md\"},{\"text\":\"14Typora\",\"link\":\"/articles/windows/14Typora.md\"},{\"text\":\"15miniconda+pycharm+CUDA\",\"link\":\"/articles/windows/15miniconda+pycharm+CUDA.md\"},{\"text\":\"16欧拉系统安装GPU驱动\",\"link\":\"/articles/windows/16欧拉系统安装GPU驱动.md\"}]}]},\"outline\":{\"level\":[1,3]},\"editLink\":{\"pattern\":\"https://github.com/mingriyingying/mingriyingying.github.io/blob/master/docs/:path\",\"text\":\"Edit this page on GitHub\"},\"lastUpdated\":{\"text\":\"Updated at\",\"formatOptions\":{\"dateStyle\":\"short\",\"timeStyle\":\"medium\"}},\"docFooter\":{\"prev\":false,\"next\":false}},\"locales\":{},\"scrollOffset\":90,\"cleanUrls\":false}");</script>
    
  </body>
</html>